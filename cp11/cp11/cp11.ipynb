{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Práctica #11 (Compilación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta clase estaremos implementando un **generador de parsers LR(1)**. Procederemos de forma análoga a la clase anterior: primero implementaremos el mecanismo de construcción del **autómata LR(1)** y posteriormente heredaremos de **Shift-Reduce parser** para llenar la tabla **Action-Goto** de forma acorde.\n",
    "\n",
    "Comencemos por importar la clase `Grammar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajaremos sobre el lenguaje de expresiones que usamos en la última conferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Terminals:\n",
      "\tE, A\n",
      "Terminals:\n",
      "\t=, +, int\n",
      "Productions:\n",
      "\t[E -> A = A, E -> int, A -> int + A, A -> int]\n"
     ]
    }
   ],
   "source": [
    "G = Grammar()\n",
    "E = G.NonTerminal('E', True)\n",
    "A = G.NonTerminal('A')\n",
    "equal, plus, num = G.Terminals('= + int')\n",
    "\n",
    "E %=  A + equal + A | num\n",
    "A %= num + plus + A | num\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items\n",
    "\n",
    "Usaremos la implementación de `Item` provista en `cmp.pycompiler` para modelar los items LR(1). Esta vez haremos uso del parámetro `lookaheads` que se especifica en el constructor de la clase `Item` para almacenar justamente los `lookaheads` de los items LR(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Item\n",
    "\n",
    "item = Item(E.productions[0], 0, lookaheads=[G.EOF, plus])\n",
    "print('item:', item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se incluyó la función `Preview` a cada item. Esta devuelve todas las posibles cadenas que resultan de concatenar _\"lo que queda por leer del item tras saltarse `skip=1` símbolos\"_ con los posibles lookaheads. Esta función nos será útil, pues sabemos que el lookahead de los items LR(1) se obtiene de calcular el `first` de estas cadenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for preview in item.Preview():\n",
    "    print('item.Preview:', preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clausura de un conjunto de items LR(1)\n",
    "\n",
    "Como primer paso para calcular la clausura, implementaremos la función `expand`. Esta recibe un item LR(1) y devuelve el conjunto de items que sugiere incluir (directamente) debido a la presencia de un `.` delante de un no terminal.\n",
    "\n",
    "> expand(\"$Y \\to \\alpha . X \\delta, c$\") = { \"$X \\to . \\beta, b$\" | $b \\in First(\\delta c)$ }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.utils import ContainerSet\n",
    "from cmp.tools.parsing import compute_firsts, compute_local_first\n",
    "\n",
    "firsts = compute_firsts(G)\n",
    "firsts[G.EOF] = ContainerSet(G.EOF)\n",
    "\n",
    "def expand(item, firsts):\n",
    "    next_symbol = item.NextSymbol\n",
    "    if next_symbol is None or not next_symbol.IsNonTerminal:\n",
    "        return []\n",
    "    \n",
    "    lookaheads = ContainerSet()\n",
    "    # Your code here!!! (Compute lookahead for child items)\n",
    "    \n",
    "    assert not lookaheads.contains_epsilon\n",
    "    # Your code here!!! (Build and return child items)\n",
    "    return\n",
    "\n",
    "for x in expand(item, firsts) :\n",
    "    print(x)\n",
    "assert str(expand(item, firsts)) == \"[A -> .int+A, {'='}, A -> .int, {'='}]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como segundo paso, implementaremos la función `compress`. Esta recibe un conjunto de items LR(1) y devuelve el mismo conjunto pero en el que los items con mismo centro están unidos (se combinan los lookahead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(items):\n",
    "    centers = {}\n",
    "\n",
    "    for item in items:\n",
    "        center = item.Center()\n",
    "        try:\n",
    "            lookaheads = centers[center]\n",
    "        except KeyError:\n",
    "            centers[center] = lookaheads = set()\n",
    "        lookaheads.update(item.lookaheads)\n",
    "    \n",
    "    return { Item(x.production, x.pos, set(lookahead)) for x, lookahead in centers.items() }\n",
    "\n",
    "compress([\n",
    "    Item(E.productions[0], 0, lookaheads=(G.EOF,)),\n",
    "    Item(E.productions[0], 0, lookaheads=(plus,)),\n",
    "    Item(E.productions[0], 1, lookaheads=(plus,)),\n",
    "    Item(E.productions[0], 2, lookaheads=(plus,)),\n",
    "    Item(E.productions[0], 2, lookaheads=(plus,G.EOF)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clausura\n",
    "\n",
    "Finalmente implementaremos la función clausura de un conjunto de items LR(1). Recordemos que:\n",
    "\n",
    "> $CL(I) = I \\cup \\{ X \\rightarrow .\\beta, b\\}$ tales que:\n",
    "> - $Y \\rightarrow \\alpha .X \\delta, c \\in CL(I)$\n",
    "> - $b \\in First(\\delta c)$.\n",
    "\n",
    "Apoyándonos en las dos funciones anteriores, debería resultar relativamente simple. Como de costumbre para los algoritmos de este tipo, utilizaremos una técnica de punto fijo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure_lr1(items, firsts):\n",
    "    closure = ContainerSet(*items)\n",
    "    \n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        \n",
    "        new_items = ContainerSet()\n",
    "        # Your code here!!!\n",
    "\n",
    "        changed = closure.update(new_items)\n",
    "        \n",
    "    return compress(closure)\n",
    "\n",
    "closure = closure_lr1([item, item.NextItem().NextItem()], firsts)\n",
    "for x in closure:\n",
    "    print(x)\n",
    "\n",
    "expected = {\n",
    "    Item(E.productions[0], 0, lookaheads=(plus, G.EOF)),\n",
    "    Item(E.productions[0], 2, lookaheads=(plus, G.EOF)),\n",
    "    Item(A.productions[0], 0, lookaheads=(plus, G.EOF, equal)),\n",
    "    Item(A.productions[1], 0, lookaheads=(plus, G.EOF, equal)),\n",
    "}\n",
    "assert closure == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goto\n",
    "\n",
    "Se provee la implementación de la función `goto(Ii, s)`. Recordemos que:\n",
    "\n",
    "> $Goto(I,X) = CL(\\{ Y \\rightarrow \\alpha X. \\beta, c | Y \\rightarrow \\alpha .X \\beta, c \\in I \\})$\n",
    "\n",
    "La función recibe como parámetro un conjunto de items y un símbolo, y devuelve el conjunto `goto(items, symbol)`. El método permite setear el parámentro `just_kernel=True` para calcular solamente el conjunto de items kernels en lugar de todo el conjunto de items. En caso contrario, se debe proveer el conjunto con los `firsts` de la gramática, puesto que serán usados al calcular la clausura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goto_lr1(items, symbol, firsts=None, just_kernel=False):\n",
    "    assert just_kernel or firsts is not None, '`firsts` must be provided if `just_kernel=False`'\n",
    "    items = frozenset(item.NextItem() for item in items if item.NextSymbol == symbol)\n",
    "    return items if just_kernel else closure_lr1(items, firsts)\n",
    "\n",
    "goto = goto_lr1([item], A, firsts)\n",
    "print(goto)\n",
    "assert  goto == {\n",
    "    Item(E.productions[0], 1, lookaheads=(plus, G.EOF))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción del autómata LR(1)\n",
    "\n",
    "Implementemos el algoritmo para construir el autómata LR(1). Recordemos de conferencia que:\n",
    "- El estado inicial es la clausura del item **`S' -> .S, $`**.\n",
    "- Todos los estados son finales.\n",
    "- Las transiciones ocurren con terminales y no terminales.\n",
    "- La función de transición está dada por la función **goto**.\n",
    "    - `f(Ii, c) = Goto(Ii, c)`\n",
    "\n",
    "_**OJO:** Intente usar solo los items kernel al comparar los estados._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.automata import State, multiline_formatter\n",
    "\n",
    "def build_LR1_automaton(G):\n",
    "    assert len(G.startSymbol.productions) == 1, 'Grammar must be augmented'\n",
    "    \n",
    "    firsts = compute_firsts(G)\n",
    "    firsts[G.EOF] = ContainerSet(G.EOF)\n",
    "    \n",
    "    start_production = G.startSymbol.productions[0]\n",
    "    start_item = Item(start_production, 0, lookaheads=(G.EOF,))\n",
    "    start = frozenset([start_item])\n",
    "    \n",
    "    closure = closure_lr1(start, firsts)\n",
    "    automaton = State(frozenset(closure), True)\n",
    "    \n",
    "    pending = [ start ]\n",
    "    visited = { start: automaton }\n",
    "    \n",
    "    while pending:\n",
    "        current = pending.pop()\n",
    "        current_state = visited[current]\n",
    "        \n",
    "        for symbol in G.terminals + G.nonTerminals:\n",
    "            # Your code here!!! (Get/Build `next_state`)\n",
    "            \n",
    "            current_state.add_transition(symbol.Name, next_state)\n",
    "    \n",
    "    automaton.set_formatter(multiline_formatter)\n",
    "    return automaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que este autómata, a pesar de presentar diferencias con el autómata LR(0), continua reconociendo el lenguaje de los prefijos viables de una gramática: cadenas que pueden ocurrir en la pila durante el parseo de una cadena válida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automaton = build_LR1_automaton(G.AugmentedGrammar())\n",
    "\n",
    "assert automaton.recognize('E')\n",
    "assert automaton.recognize(['A','=','int'])\n",
    "assert automaton.recognize(['int','+','int','+','A'])\n",
    "\n",
    "assert not automaton.recognize(['int','+','A','+','int'])\n",
    "assert not automaton.recognize(['int','=','int'])\n",
    "\n",
    "automaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser LR(1) canónico\n",
    "\n",
    "Reutilizaremos la implementación base de parser Shift-Reduce que terminamos en la clase anterior. Recordemos que esta clase se encarga de todo el algoritmo de parsing, dejando en mano de sus herederos la implementación concreta del método `_build_parsing_table` para llenar la tabla Acción-Goto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.tools.parsing import ShiftReduceParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo llena la tabla un parser LR(1)?\n",
    "\n",
    "- **Sea** \"$X \\to \\alpha .c \\omega, s$\" un item del estado $I_i$ y $Goto(I_i,c) = I_j$.  \n",
    "**Entonces** $ACTION[I_i,c] = `S_j`$.\n",
    "\n",
    "- **Sea** \"$X \\to \\alpha ., s$\" un item del estado $I_i$.  \n",
    "**Entonces** $ACTION[I_i,s] = `R_k`$ (producción `k` es $X \\to \\alpha$).\n",
    "\n",
    "- **Sea** $I_i$ el estado que contiene el item \"$S' \\to S., \\$$\" ($S'$ distinguido).  \n",
    "**Entonces** $ACTION[I_i,\\$] = `OK`$.\n",
    "\n",
    "- **Sea** \"$X \\to \\alpha .Y \\omega, s$\" item del estado $I_i$ y $Goto(I_i,Y) = I_j$.  \n",
    "**Entonces** $GOTO[I_i,Y] = j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR1Parser(ShiftReduceParser):\n",
    "    def _build_parsing_table(self):\n",
    "        G = self.G.AugmentedGrammar(True)\n",
    "        \n",
    "        automaton = build_LR1_automaton(G)\n",
    "        for i, node in enumerate(automaton):\n",
    "            if self.verbose: print(i, '\\t', '\\n\\t '.join(str(x) for x in node.state), '\\n')\n",
    "            node.idx = i\n",
    "\n",
    "        for node in automaton:\n",
    "            idx = node.idx\n",
    "            for item in node.state:\n",
    "                # Your code here!!!\n",
    "                # - Fill `self.Action` and `self.Goto` according to `item`)\n",
    "                # - Feel free to use `self._register(...)`)\n",
    "                pass\n",
    "        \n",
    "    @staticmethod\n",
    "    def _register(table, key, value):\n",
    "        assert key not in table or table[key] == value, 'Shift-Reduce or Reduce-Reduce conflict!!!'\n",
    "        table[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando\n",
    "\n",
    "Construyamos un parser LR(1) para la gramática de expresiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LR1Parser(G, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tablas\n",
    "\n",
    "Para visualizar las tablas Action y Goto usaremos la clase `DataFrame` de `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def encode_value(value):\n",
    "    try:\n",
    "        action, tag = value\n",
    "        if action == ShiftReduceParser.SHIFT:\n",
    "            return 'S' + str(tag)\n",
    "        elif action == ShiftReduceParser.REDUCE:\n",
    "            return repr(tag)\n",
    "        elif action ==  ShiftReduceParser.OK:\n",
    "            return action\n",
    "        else:\n",
    "            return value\n",
    "    except TypeError:\n",
    "        return value\n",
    "\n",
    "def table_to_dataframe(table):\n",
    "    d = {}\n",
    "    for (state, symbol), value in table.items():\n",
    "        value = encode_value(value)\n",
    "        try:\n",
    "            d[state][symbol] = value\n",
    "        except KeyError:\n",
    "            d[state] = { symbol: value }\n",
    "\n",
    "    return DataFrame.from_dict(d, orient='index', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que:\n",
    "\n",
    "- Debe haber a lo sumo una opción en cada celda.\n",
    "\n",
    "- Deben aparecer todos los estados (salvo $I_0$) entre **ACTION** y **GOTO**.\n",
    "\n",
    "- Deben aparecer todas las producciones entre los $R_k$ de **ACTION**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(table_to_dataframe(parser.action))\n",
    "display(table_to_dataframe(parser.goto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parseando ...\n",
    "\n",
    "Trabajemos sobre la cadena `int + int = int + int`. Si el parser está correctamente implementado deberíamos obtener una derivación extrema derecha en reverso que parta de la oración y llegue al símbolo distinguido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation = parser([num, plus, num, equal, num, plus, num, G.EOF])\n",
    "\n",
    "assert str(derivation) == '[A -> int, A -> int + A, A -> int, A -> int + A, E -> A = A]'\n",
    "\n",
    "derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propuestas\n",
    "\n",
    "- Implemente un generador de parsers **LALR(1)**.\n",
    "- Complete el pipeline de evaluación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
