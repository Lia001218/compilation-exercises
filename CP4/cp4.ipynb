{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Pr\u00e1ctica #4 (Compilaci\u00f3n)\n",
    "\n",
    "En esta clase estaremos implementando un mecanismo gen\u00e9rico de **evaluaci\u00f3n** de cadenas a partir de la especificaci\u00f3n de **atributos** y **reglas** en la gram\u00e1tica. Dise\u00f1aremos concretamente las reglas de evaluaci\u00f3n para la gram\u00e1tica del subconjunto de `HULK` con que hemos trabajado desde clases anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gram\u00e1ticas Atributadas\n",
    "\n",
    "Recordemos que una **gram\u00e1tica atributada** es una tupla $<G,A,R>$, donde:\n",
    "\n",
    "* $G = <S,P,N,T>$ es una gram\u00e1tica libre del contexto,\n",
    "* $A$ es un conjunto de atributos de la forma $X \\cdot a$\n",
    "  donde $X \\in N \\cup T$ y $a$ es un identificador \u00fanico entre todos los atributos del mismo s\u00edmbolo, y\n",
    "* $R$ es un conjunto de reglas de la forma $<p_i, r_i>$ donde $p_i \\in P$ es una producci\u00f3n $X \\to Y_1, \\ldots, Y_n$, y $r_i$ es una regla de la forma:\n",
    "    1. $X \\cdot a = f(Y_1 \\cdot a_1, \\ldots, Y_n \\cdot a_n)$, o\n",
    "    2. $Y_i \\cdot a = f(X \\cdot a_0, Y_1 \\cdot a_1, \\ldots, Y_n \\cdot a_n)$.\n",
    "\n",
    "Los atributos se dividen en dos conjuntos disjuntos: _atributos heredados_ y _atributos sintetizados_. En el caso (1) decimos que `a` es un _atributo sintetizado_, y en el caso (2), un _atributo heredado_.\n",
    "\n",
    "Seg\u00fan esta distinci\u00f3n, estudiamos en conferencia condiciones suficientes para que una gram\u00e1tica fuera evaluable:\n",
    "\n",
    "- Una gram\u00e1tica atributada es **s-atributada** si y solo si, para toda regla $r_i$ asociada a una producci\u00f3n $X \\to Y_1, \\ldots, Y_n$, se cumple que $r_i$ es de la forma $X \\cdot a = f(Y_1 \\cdot a_1, \\ldots, Y_n \\cdot a_n)$.\n",
    "\n",
    "- Una gram\u00e1tica atributada es **l-atributada** si y solo si toda regla $r_i$ asociada a una producci\u00f3n $X \\to Y_1, \\ldots, Y_n$ es de una de las siguientes formas:\n",
    "    - $X \\cdot a = f(Y_1 \\cdot a_1, \\ldots, Y_n \\cdot a_n)$, \u00f3\n",
    "    - $Y_i \\cdot a_i = f(X \\cdot a, Y_1 \\cdot a_1, \\ldots, Y_{i-1} \\cdot a_{i-1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especificaci\u00f3n en _Python_\n",
    "\n",
    "Continuaremos trabajando con la _API_ para gram\u00e1ticas presentada en la clase anterior. Esta vez, la definici\u00f3n de s\u00edmbolo, oraci\u00f3n, producci\u00f3n, gram\u00e1tica, etc. se encuentra en el m\u00f3dulo `cmp` que se distribuye junto a este _notebook_.\n",
    "\n",
    "Procedamos a importar las clases y m\u00e9todos que nos interesan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Symbol, NonTerminal, Terminal, EOF, Sentence, Epsilon, Production, Grammar\n",
    "from cmp.utils import pprint, inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la _API_ de gram\u00e1ticas se a\u00f1ade una nueva clase: `AttributeProduction`. Con esta clase modelaremos las producciones de las gram\u00e1ticas atributadas. Cada una de estas producciones se compone por:\n",
    "- Un no terminal como cabecera. Accesible a trav\u00e9s del campo `Left`.\n",
    "- Una oraci\u00f3n como cuerpo. Accesible a trav\u00e9s del campo `Right`.\n",
    "- Un conjunto de reglas para evaluar los atributos. Accesible a trav\u00e9s del campo `atributes`.\n",
    "\n",
    "Las producciones no deben ser instanciadas directamente con la aplicaci\u00f3n de su constructor. En su lugar, se presentan las siguientes facilidades para formar producciones a partir de una instancia `G` de `Grammar` y un grupo de terminales y no terminales:\n",
    "- Para definir una producci\u00f3n de la forma $B_0 \\to B_1 B_2 ... B_n$ que:\n",
    "    - Asocia a $B_0$ una regla $\\lambda_0$ para sintetizar sus atributos, y\n",
    "    - Asocia a $B_1 \\dots B_n$ las reglas $\\lambda_1 \\dots \\lambda_n$ que hereden sus atributos respectivamentes.\n",
    "    \n",
    "    ```python\n",
    "    B0 %= B1 + B2 + ... + Bn, lambda0, lambda1, lambda2, ..., lambdaN\n",
    "    ```\n",
    "    \n",
    "> Donde `lambda0`, `lambda1`, ..., `lambdaN` son funciones que reciben 2 par\u00e1metros.\n",
    "> 1. Como primer par\u00e1metro los atributos heredados que se han computado para cada instancia de s\u00edmbolo en la producci\u00f3n, durante la aplicaci\u00f3n de esa instancia de producci\u00f3n espec\u00edficamente. Los valores se acceden desde una lista de `n + 1` elementos. Los valores se ordenan seg\u00fan aparecen los s\u00edmbolos en la producci\u00f3n, comenzando por la cabecera. Nos referiremos a esta colecci\u00f3n como `inherited`.\n",
    "> 2. Como segundo par\u00e1metro los atributos sintetizados que se han computado para cada instancia de s\u00edmbolo en la producci\u00f3n, durante la aplicaci\u00f3n de esa instancia de producci\u00f3n espec\u00edficamente. Sigue la misma estructura que el primer par\u00e1metro. Nos referiremos a esta colecci\u00f3n como `synteticed`.\n",
    ">\n",
    "> La funci\u00f3n `lambda0` sintetiza los atributos de la cabecera. La evaluaci\u00f3n de dicha funci\u00f3n produce el valor de `synteticed[0]`. El resto de los atributos sintetizados de los s\u00edmbolos de la producci\u00f3n se calcula de la siguiente forma:\n",
    "> - En caso de que el s\u00edmbolo sea un terminal, eval\u00faa como su lexema.\n",
    "> - En caso de que el s\u00edmbolo sea un no terminal, se obtiene de evaluar la funci\u00f3n `lambda0` en la instancia de producci\u00f3n correspondiente.\n",
    ">\n",
    "> La funci\u00f3n `lambda_i`, con `i` entre 1 y `n`, computa los atributos heredados de la i-\u00e9sima ocurrencia de s\u00edmbolo en la producci\u00f3n. La evaluaci\u00f3n de dicha funci\u00f3n produce el valor de `inherited[i]`. El valor de `inherited[0]` se obtiene como el atributo que hered\u00f3 la instancia concreta del s\u00edmbolo en la cabecera antes de comenzar a aplicar la producci\u00f3n.\n",
    "\n",
    "- En caso de que no se vaya a sociar una regla a un s\u00edmbolo se incluir\u00e1 un `None`.\n",
    "    ```python\n",
    "       E %= T + X   ,  lambda h,s: s[2]  ,    None    ,   lambda h,s: s[1]\n",
    "    # ___________     ________________     ________      ________________\n",
    "    # producci\u00f3n  |    regla para E    |  sin regla  |     regla para X \n",
    "    ```\n",
    "    > `[0]:` **`lambda h,s: s[2]`** al ser `lambda0` sintetiza el valor de `E`. Lo hace en funci\u00f3n del valor que sintetiza `X` (accesible desde `s[2]`).  \n",
    "    > `[1]:` **`None`** al ser `lambda1` indica que no se incluye regla para heredar valor a `T`.  \n",
    "    > `[2]:` **`lambda h,s: s[1]`** al ser `lambda2` hereda un valor a `X`. Lo hace en funci\u00f3n del valor que sintetiza `T` (accesible desde `s[1]`).\n",
    "\n",
    "- No se deben definir m\u00faltiples producciones de la misma cabecera en una \u00fanica sentencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeProduction(Production):\n",
    "\n",
    "    def __init__(self, nonTerminal, sentence, attributes):\n",
    "        if not isinstance(sentence, Sentence) and isinstance(sentence, Symbol):\n",
    "            sentence = Sentence(sentence)\n",
    "        super(AttributeProduction, self).__init__(nonTerminal, sentence)\n",
    "\n",
    "        self.attributes = attributes\n",
    "\n",
    "    def __str__(self):\n",
    "        return '%s := %s' % (self.Left, self.Right)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '%s -> %s' % (self.Left, self.Right)\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield self.Left\n",
    "        yield self.Right\n",
    "\n",
    "\n",
    "    @property\n",
    "    def IsEpsilon(self):\n",
    "        return self.Right.IsEpsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gram\u00e1tica de HULK\n",
    "\n",
    "Completemos entonces la siguiente especificaci\u00f3n de la gram\u00e1tica para `HULK` a\u00f1adiendo las reglas necesarias.\n",
    "\n",
    "`E` $\\rightarrow$ `T X`  \n",
    "`X` $\\rightarrow$ `+ T X | - T X | epsilon`  \n",
    "`T` $\\rightarrow$ `F Y`  \n",
    "`Y` $\\rightarrow$ `* F Y | / F Y | epsilon`  \n",
    "`F` $\\rightarrow$ `( E ) | num`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Grammar()\n",
    "E = G.NonTerminal('E', True)\n",
    "T, F, X, Y = G.NonTerminals('T F X Y')\n",
    "plus, minus, star, div, opar, cpar, num = G.Terminals('+ - * / ( ) num')\n",
    "\n",
    "############################ BEGIN PRODUCTIONS ############################\n",
    "# ======================================================================= #\n",
    "#                                                                         #\n",
    "# ========================== { E --> T X } ============================== #\n",
    "#                                                                         #\n",
    "# E %= T + X, lambda h,s: s[2], None, lambda h,s: s[1]                    #\n",
    "#                                                                         #\n",
    "# =================== { X --> + T X | - T X | epsilon } ================= #\n",
    "#                                                                         #\n",
    "# X %= plus + T + X, None, None, None, None                               #\n",
    "# X %= minus + T + X, None, None, None, None                              #\n",
    "# X %= G.Epsilon, None                                                    #\n",
    "#                                                                         #\n",
    "# ============================ { T --> F Y } ============================ #\n",
    "#                                                                         #\n",
    "# T %= F + Y, None, None, None                                            #\n",
    "#                                                                         #\n",
    "# ==================== { Y --> * F Y | / F Y | epsilon } ================ #\n",
    "#                                                                         #\n",
    "# Y %= star + F + Y, None, None, None, None                               #\n",
    "# Y %= div + F + Y, None, None, None, None                                #\n",
    "# Y %= G.Epsilon, None                                                    #\n",
    "#                                                                         #\n",
    "# ======================= { F --> num | ( E ) } ========================= #\n",
    "# F %= num, None, None                                                    #\n",
    "# F %= opar + E + cpar, None, None, None, None                            #\n",
    "#                                                                         #\n",
    "# ======================================================================= #\n",
    "############################# END PRODUCTIONS #############################\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la clase pasada implementamos los algoritmos para calcular los conjuntos `first` y `follow`. Esta vez utilizaremos dichos conjuntos ya precomputados para nuestro subconjunto de `HULK`. Pasemos a importarlos desde el m\u00f3dulo `utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.languages import BasicHulk\n",
    "\n",
    "hulk = BasicHulk(G)\n",
    "firsts, follows = hulk.firsts, hulk.follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma similar procederemos con los m\u00e9todos `build_parsing_table` y `metodo_predictivo_no_recursivo` que devuelven la tabla _LL(1)_ y el parser _LL(1)_ respectivamente. Pasemos a importarlos desde el m\u00f3dulo `tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.tools.parsing import build_parsing_table\n",
    "from cmp.tools.parsing import deprecated_metodo_predictivo_no_recursivo as metodo_predictivo_no_recursivo\n",
    "\n",
    "# Testing table\n",
    "M = build_parsing_table(G, firsts, follows)\n",
    "assert M == hulk.table\n",
    "\n",
    "# Testing parser\n",
    "parser = metodo_predictivo_no_recursivo(G, M)\n",
    "left_parse = parser([num, star, num, star, num, plus, num, star, num, plus, num, plus, num, G.EOF])\n",
    "assert left_parse == [ \n",
    "   Production(E, Sentence(T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, Sentence(star, F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, Sentence(star, F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, Sentence(plus, T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, Sentence(star, F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, Sentence(plus, T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, Sentence(plus, T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, G.Epsilon),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluaci\u00f3n\n",
    "\n",
    "En la clase anterior asumimos que la cadena de entrada que queremos parsear es una lista de s\u00edmbolos terminales. A\u00fan as\u00ed, notemos que en realidad la entrada no est\u00e1 compuesta solamente por estos s\u00edmbolos. El parser trabaja con una secuencia de _tokens_, que como ya sabemos se componen de un _lexema_ y un _tipo_. Los s\u00edmbolos terminales son justamente los tipos de los tokens y, por tanto, son los valores relevantes al parsear. Sin embargo, nuestro problema no termina al parsear sino que debemos ser capaces de evaluar, en el lenguaje actual, la expresi\u00f3n de `HULK` que se di\u00f3 como entrada. Para ello, el lexema de los tokens juega un papel esencial ya que son estos los que capturan las particularidades de los valores de entrada. Por ejemplo, en el caso de `HULK`, para saber qu\u00e9 dos n\u00fameros se est\u00e1n operando es necesario considerar los lexemas.\n",
    "\n",
    "A continuaci\u00f3n se implementa la clase `Token` usada para modelar los tokens. Se puede acceder al lexema y tipo de cada token a trav\u00e9s de los campos `lex` y `token_type` respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    \"\"\"\n",
    "    Basic token class. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lex : str\n",
    "        Token's lexeme.\n",
    "    token_type : Enum\n",
    "        Token's type.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lex, token_type):\n",
    "        self.lex = lex\n",
    "        self.token_type = token_type\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.token_type}: {self.lex}'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifiquemos el generador de parsers para que acceda el tipo de token a trav\u00e9s de la propiedad `token_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deprecated_metodo_predictivo_no_recursivo = metodo_predictivo_no_recursivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO: No ejecute la celda anterior ($\\uparrow$) una vez ejecutadas las celdas que siguen a continuaci\u00f3n ($\\downarrow$)**\n",
    "\n",
    "Redefiniremos la implementaci\u00f3n del generador de parsers hacia una que *decore* la salida del actual. Esta nueva implementaci\u00f3n simplemente extraer\u00e1 de los tokens de entrada los respectivos tipos (`token_type`), y proceder\u00e1 de la misma forma que ya estaba implementada. Claramente, los hacemos de esta forma para reutilizar la versi\u00f3n que ya ten\u00edamos implementada, pero podr\u00edamos reescribir la implementaci\u00f3n original para que al acceder al s\u00edmbolo puntado por el cabezal (`a = w[cursor]`) accediera a su tipo a trav\u00e9s del campo `token_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_predictivo_no_recursivo(G, M):\n",
    "    parser = deprecated_metodo_predictivo_no_recursivo(G, M)\n",
    "    def updated(tokens):\n",
    "        return parser([t.token_type for t in tokens])\n",
    "    return updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R\u00e1pidamente podemos comprobar la efectividad del cambio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '5.9 + 4'\n",
    "tokens = [ Token('5.9', num), Token('+', plus), Token('4', num), Token('$', G.EOF) ]\n",
    "parser = metodo_predictivo_no_recursivo(G, M)\n",
    "left_parse = parser(tokens)\n",
    "left_parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasemos finalmente a implementar un algoritmo de evaluaci\u00f3n de la secuencia de tokens a partir del parse izquierdo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_parse(left_parse, tokens):\n",
    "    if not left_parse or not tokens:\n",
    "        return\n",
    "    \n",
    "    left_parse = iter(left_parse)\n",
    "    tokens = iter(tokens)\n",
    "    result = evaluate(next(left_parse), left_parse, tokens)\n",
    "    \n",
    "    assert isinstance(next(tokens).token_type, EOF)\n",
    "    return result\n",
    "    \n",
    "\n",
    "def evaluate(production, left_parse, tokens, inherited_value=None):\n",
    "    head, body = production\n",
    "    attributes = production.attributes\n",
    "    \n",
    "    # Insert your code here ...\n",
    "    # > synteticed = ...\n",
    "    # > inherited = ...\n",
    "    # Anything to do with inherited_value?\n",
    "\n",
    "    for i, symbol in enumerate(body, 1):\n",
    "        if symbol.IsTerminal:\n",
    "            assert inherited[i] is None\n",
    "            # Insert your code here ...\n",
    "        else:\n",
    "            next_production = next(left_parse)\n",
    "            assert symbol == next_production.Left\n",
    "            # Insert your code here ...\n",
    "    \n",
    "    # Insert your code here ...\n",
    "    # > return ...\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y enseguida podemos comprobar la correctitud del algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate_parse(left_parse, tokens)\n",
    "print(f'{text} = {result}')\n",
    "assert result == 9.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completando el pipeline\n",
    "\n",
    "Implementemos nuevamente un tokenizer muy b\u00e1sico. Asumiremos como de costumbre que las unidades l\u00e9xicas relevantes est\u00e1n separadas por espacio (o sea, que los n\u00fameros y operadores est\u00e1n separados por al menos un espacio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_tokens = {\n",
    "    '+'  :   Token( '+', plus  ),\n",
    "    '-'  :   Token( '-', minus ),\n",
    "    '*'  :   Token( '*', star  ),\n",
    "    '/'  :   Token( '/', div   ),\n",
    "    '('  :   Token( '(', opar  ),\n",
    "    ')'  :   Token( ')', cpar  ),\n",
    "}\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "\n",
    "    for item in text.split():\n",
    "        try:\n",
    "            float(item)\n",
    "            token = Token(item, num)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                token = fixed_tokens[item]\n",
    "            except:\n",
    "                raise Exception('Undefined token')\n",
    "        tokens.append(token)\n",
    "\n",
    "    eof = Token('$', G.EOF)\n",
    "    tokens.append(eof)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos algunas cadenas. Se realizar\u00e1 la siguiente cadena de transformaciones:\n",
    "```\n",
    "Entrada -> Tokens -> Parse Izquierdo -> Resultado\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1 - 1 - 1'\n",
    "tokens = tokenize_text(text)\n",
    "pprint(tokens, '================Tokens================')\n",
    "left_parse = parser(tokens)\n",
    "pprint(left_parse, '==============Left-Parse==============')\n",
    "result = evaluate_parse(left_parse, tokens)\n",
    "pprint(f'{text} = {result}', '================Result================')\n",
    "assert result == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1 - ( 1 - 1 )'\n",
    "tokens = tokenize_text(text)\n",
    "pprint(tokens, '================Tokens================')\n",
    "left_parse = parser(tokens)\n",
    "pprint(left_parse, '==============Left-Parse==============')\n",
    "result = evaluate_parse(left_parse, tokens)\n",
    "pprint(f'{text} = {result}', '================Result================')\n",
    "assert result == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propuestas\n",
    "\n",
    "- Con el objetivo de simplificar la implementaci\u00f3n de los algoritmos en la clase, la evaluaci\u00f3n de los atributos se realiz\u00f3 posteriormente a que se obtuviera completamente el parse izquierdo. Sin embargo, vimos en conferencia que la evaluaci\u00f3n de los atributos puede realizarse junto al proceso de parsing LL(1) si la gram\u00e1tica es _L-atributada_. Realice las modificaciones pertinentes para evaluar los atributos a medida que se parsea la cadena."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}