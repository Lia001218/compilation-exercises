{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Pr\u00e1ctica #3 (Compilaci\u00f3n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminares\n",
    "\n",
    "El objetivo de esta clase es implementar un **generador autom\u00e1tico de parsers LL(1)**. Tal generador recibir\u00eda como entrada la especificaci\u00f3n de una gram\u00e1tica. Siguiendo esta idea, primeramente deber\u00edamos ser capaces de representar de forma clara y c\u00f3moda tal \"especificaci\u00f3n\" de la gram\u00e1tica.\n",
    "\n",
    "A continuaci\u00f3n se describen un n\u00famero de clases que nos ser\u00e1n \u00fatiles para construir, de forma concisa, una gram\u00e1tica como un objeto de **Python**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S\u00edmbolos\n",
    "\n",
    "Modelaremos los **s\u00edmbolos** del lenguaje con la clase `Symbol`. Esta clase funcionar\u00e1 como base para la definici\u00f3n de terminales y no terminales. Entre las funcionalidades b\u00e1sicas de los s\u00edmbolos tenemos que:\n",
    "- Pueden ser agrupados con el operador `+` para formar oraciones.\n",
    "- Podemos conocer si representa la cadena especial **epsilon** a trav\u00e9s de la propiedad `IsEpsilon` que poseen todas las instancias.\n",
    "- Podemos acceder a la gram\u00e1tica en la que se defini\u00f3 a trav\u00e9s del campo `Grammar` de cada instancia.\n",
    "- Podemos consultar la notaci\u00f3n del s\u00edmbolo a trav\u00e9s del campo `Name` de cada instancia.\n",
    "\n",
    "Los s\u00edmbolos no deben ser instanciados directamente (ni sus descendiente) con la aplicaci\u00f3n de su constructor. En su lugar, utilizaremos una sintaxis descrita m\u00e1s adelante para definirlos junto a la especificaci\u00f3n de la gram\u00e1tica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Terminales\n",
    "\n",
    "Los s\u00edmbolos **no terminales** los modelaremos con la clase `NonTerminal`. Dicha clase extiende la clase `Symbol` para:\n",
    "- A\u00f1adir noci\u00f3n de las producci\u00f3n que tiene al no terminal como cabecera. Estas pueden ser conocidas a trav\u00e9s del campo `productions` de cada instancia.\n",
    "- Permitir a\u00f1adir producciones para ese no terminal a trav\u00e9s del operador `%=`.\n",
    "- Incluir propiedades `IsNonTerminal` - `IsTerminal` que devolveran `True` - `False` respectivamente.\n",
    "\n",
    "Los no terminales no deben ser instanciados directamente con la aplicaci\u00f3n de su constructor. En su lugar, se presentan las siguientes facilidades para definir no terminales a partir de una instancia `G` de `Grammar`:\n",
    "- Para definir un \u00fanico no terminal:\n",
    "    ```python\n",
    "    non_terminal_var = G.NonTerminal('<non-terminal-name>')\n",
    "    # non_terminal_var    <--- variable en la que guardaremos la referencia al no terminal.\n",
    "    # <non-terminal-name> <--- nombre concreto del no terminal.\n",
    "    ```\n",
    "- Para definir el s\u00edmbolo distingido:\n",
    "    ```python\n",
    "    start_var = G.NonTerminal('<start-name>', True)\n",
    "    # start_var    <--- variable en la que guardaremos la referencia s\u00edmbolo distinguido.\n",
    "    # <start-name> <--- nombre concreto del s\u00edmbolo distinguido.\n",
    "    ```\n",
    "- Para definir m\u00faltiples no terminales:\n",
    "    ```python\n",
    "    var1, var2, ..., varN = G.NonTerminals('<name1> <name2> ... <nameN>')\n",
    "    # var1, var2, ..., varN    <--- variables en las que guardaremos las referencias a los no terminales.\n",
    "    # <name1> <name2> ... <nameN> <--- nombres concretos del no terminales (separados por espacios).\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import NonTerminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminales\n",
    "\n",
    "Los s\u00edmbolos **terminales** los modelaremos con la clase `Terminal`. Dicha clase extiende la clase `Symbol` para:\n",
    "- Incluir propiedades `IsNonTerminal` - `IsTerminal` que devolveran `True` - `False` respectivamente.\n",
    "\n",
    "Los terminales no deben ser instanciados directamente con la aplicaci\u00f3n de su constructor. En su lugar, se presentan las siguientes facilidades para definir no terminales a partir de una instancia `G` de `Grammar`:\n",
    "- Para definir un \u00fanico terminal:\n",
    "    ```python\n",
    "    terminal_var = G.Terminal('<terminal-name>')\n",
    "    # terminal_var    <--- variable en la que guardaremos la referencia al terminal.\n",
    "    # <terminal-name> <--- nombre concreto del terminal.\n",
    "    ```\n",
    "- Para definir m\u00faltiples terminales:\n",
    "    ```python\n",
    "    var1, var2, ..., varN = G.Terminals('<name1> <name2> ... <nameN>')\n",
    "    # var1, var2, ..., varN    <--- variables en las que guardaremos las referencias a los terminales.\n",
    "    # <name1> <name2> ... <nameN> <--- nombres concretos del terminales (separados por espacios).\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fin de Cadena (EOF, *$*)\n",
    "Modelaremos el s\u00edmbolo de fin de cadena con la clase `EOF`. Dicha clase extiende la clases `Terminal` para heradar su comportamiento.\n",
    "\n",
    "La clase `EOF` no deber\u00e1 ser instanciada directamente con la aplicaci\u00f3n de su constructor. En su lugar, una instancia concreta para determinada gram\u00e1tica `G` de `Grammar` se construir\u00e1 autom\u00e1ticamente y ser\u00e1 accesible a trav\u00e9s de `G.EOF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oraciones y Formas Oracionales\n",
    "\n",
    "Modelaremos los **oraciones** y **formas oracionales** del lenguaje con la clase `Sentence`. Esta clase funcionar\u00e1 como una colecci\u00f3n de terminales y no terminales. Entre las funcionalidades b\u00e1sicas que provee tenemos que nos :\n",
    "- Permite acceder a los s\u00edmbolos que componen la oraci\u00f3n a trav\u00e9s del campo `_symbols` de cada instancia.\n",
    "- Permite conocer si la oraci\u00f3n es completamente vac\u00eda a trav\u00e9s de la propiedad `IsEpsilon`.\n",
    "- Permite obtener la concatenaci\u00f3n con un s\u00edmbolo u otra oraci\u00f3n aplicando el operador `+`.\n",
    "- Permite conocer la longitud de la oraci\u00f3n (cantidad de s\u00edmbolos que la componen) utilizando la funci\u00f3n *build-in* de python `len(...)`.\n",
    "\n",
    "Las oraciones pueden ser agrupadas usando el operador `|`. Esto nos ser\u00e1 conveniente para definir las producciones las producciones que tengan la misma cabeza (no terminal en la parte izquierda) en una \u00fanica sentencia. El grupo de oraciones se maneja con la clase `SentenceList`.\n",
    "\n",
    "No se deben crear instancias de `Sentence` y `SentenceList` directamente con la aplicaci\u00f3n de los respectivos constructores. En su lugar, usaremos el operador `+` entre s\u00edmbolos para formar las oraciones, y el operador `|` entre oraciones para agruparlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Sentence, SentenceList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon\n",
    "\n",
    "Modelaremos tanto la **cadena vac\u00eda** como el s\u00edmbolo que la representa: **epsilon** ($\\epsilon$), en la misma clase: `Epsilon`. Dicha clase extiende las clases `Terminal` y `Sentence` por lo que ser comporta como ambas. Sobreescribe la implementaci\u00f3n del m\u00e9todo `IsEpsilon` para indicar que en efecto toda instancia de la clase reprensenta **epsilon**.\n",
    "\n",
    "La clase `Epsilon` no deber\u00e1 ser instanciada directamente con la aplicaci\u00f3n de su constructor. En su lugar, una instancia concreta para determinada gram\u00e1tica `G` de `Grammar` se construir\u00e1 autom\u00e1ticamente y ser\u00e1 accesible a trav\u00e9s de `G.Epsilon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producciones\n",
    "\n",
    "Modelaremos las **producciones** con la clase `Production`. Las funcionalidades b\u00e1sicas con que contamos son:\n",
    "- Poder acceder la cabecera (parte izquierda) y cuerpo (parte derecha) de cada producci\u00f3n a trav\u00e9s de los campos `Left` y `Right` respectivamente.\n",
    "- Consultar si la producci\u00f3n es de la forma $X \\rightarrow \\epsilon$ a trav\u00e9s de la propiedad `IsEpsilon`.\n",
    "- Desempaquetar la producci\u00f3n en cabecera y cuerpo usando asignaciones: `left, right = production`.\n",
    "\n",
    "Las producciones no deben ser instanciadas directamente con la aplicaci\u00f3n de su constructor. En su lugar, se presentan las siguientes facilidades para formar producciones a partir de una instancia `G` de `Grammar` y un grupo de terminales y no terminales:\n",
    "- Para definir una producci\u00f3n de la forma $E \\rightarrow E + T$:\n",
    "    ```python\n",
    "    E %= E + plus + T\n",
    "    ```\n",
    "- Para definir m\u00faltiples producciones de la misma cabecera en una \u00fanica sentencia ($E \\rightarrow$ $E + T$ | $E - T$ | $T$):\n",
    "    ```python\n",
    "    E %= E + plus + T | E + minus + T | T\n",
    "    ```\n",
    "- Para usar *epsilon* en una producci\u00f3n (ejemplo $S \\rightarrow$ $aS$ | $\\epsilon$) har\u00edamos:\n",
    "    ```python\n",
    "    S %= S + a | G.Epsilon\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gram\u00e1tica\n",
    "\n",
    "Modelaremos las **gram\u00e1ticas** con la clase `Grammar`. Las funcionalidades b\u00e1sicas con que contamos son:\n",
    "- Definir los s\u00edmbolos _terminales_ y _no terminales_ de la gram\u00e1tica en cuesti\u00f3n a trav\u00e9s de los m\u00e9todos `Terminal` y `Terminals` para los primeros, y `NonTerminal` y `NonTerminals` para los segundos.\n",
    "- Definir las producciones de la gram\u00e1tica a partir de la aplicaci\u00f3n del operador `%=` entre no terminales y oraciones (estas a su vez formadas por la concatenaci\u00f3n de s\u00edmbolos).\n",
    "- Acceder a **todas** las _producciones_ a trav\u00e9s del campo `Productions` de cada instancia.\n",
    "- Acceder a **todos** los _terminales_ y _no terminales_ a trav\u00e9s de los campos `terminals` y `nonTerminals` respectivamente.\n",
    "- Acceder al _s\u00edmbolo distinguido_, _epsilon_ y _fin de cadena_ a trav\u00e9s de los campos `startSymbol`, `Epsilon` y `EOF` respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo: Gram\u00e1tica de HULK\n",
    "\n",
    "A continuaci\u00f3n de muestra c\u00f3mo especificar la gram\u00e1tica LL(1) para `HULK` vista en conferencias:\n",
    "\n",
    "$ E \\rightarrow$ $TX$  \n",
    "$ X \\rightarrow$ $+TX$ | $-TX$ | $\\epsilon$  \n",
    "$ T \\rightarrow$ $FY$  \n",
    "$ Y \\rightarrow$ $*FY$ | $/FY$ | $\\epsilon$  \n",
    "$ F \\rightarrow$ $( E )$ | num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.utils import pprint, inspect\n",
    "\n",
    "G = Grammar()\n",
    "E = G.NonTerminal('E', True)\n",
    "T,F,X,Y = G.NonTerminals('T F X Y')\n",
    "plus, minus, star, div, opar, cpar, num = G.Terminals('+ - * / ( ) num')\n",
    "\n",
    "E %= T + X\n",
    "X %= plus + T + X | minus + T + X | G.Epsilon\n",
    "T %= F + Y\n",
    "Y %= star + F + Y | div + F + Y | G.Epsilon\n",
    "F %= num | opar + E + cpar\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generador de parsers LL(1)\n",
    "\n",
    "Pasemos a implementar un generador de parsers LL(1). Para ello ser\u00e1 necesario implementar un algoritmo que compute el conjunto _First_ de los s\u00edmbolos terminales, no terminales y producciones. Adem\u00e1s, implementaremos un algoritmo para computar el _Follow_ de todos los no terminales de la gram\u00e1tica.\n",
    "\n",
    "Una vez podamos calcular dichos conjuntos, construiremos una tabla con $|V_N|$ filas y $|V_t| + 1$ columnas, que representar\u00e1 la unidad de control del parser. La celda $(i,j)$ de la tabla contiene la producci\u00f3n a aplicar si al \"tratar\" de parsear el _i-\u00e9simo_ no terminal, el cabezal queda apuntando al s\u00edmbolo asociado a la columna _j_ (es un terminal o _$_). Aplicar una producci\u00f3n se reduce a consumir terminales y tratar de parsear no terminales, seg\u00fan van apareciendo en la parte derecha de la producci\u00f3n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de s\u00edmbolos\n",
    "\n",
    "Resulta conveniente manejar la pertenencia o no de *epsilon* a un conjunto como un caso extremo. Para ello usaremos la clase `ContainerSet` implementada a continuaci\u00f3n.\n",
    "- La clase funciona como un conjunto de s\u00edmbolos.\n",
    "- Permite consulta la pertenencia de _epsilon_ al conjunto.\n",
    "- Las operaciones que modifican el conjunto devuelven si hubo _cambio_ o _no_.\n",
    "- El conjunto puede ser actualizado con la adici\u00f3n de elementos individuales, `add(...)`, o a partir de otro conjunto,`update(...)` y `hard_update(...)`.\n",
    "- La actualizaci\u00f3n _sin epsilon (1)_, _con epsilon (2)_ y de _solo epsilon (3)_, ocurre a trav\u00e9s de `update(...)`, `hard_update(...)` y `epsilon_update(...)` respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContainerSet:\n",
    "    def __init__(self, *values, contains_epsilon=False):\n",
    "        self.set = set(values)\n",
    "        self.contains_epsilon = contains_epsilon\n",
    "        \n",
    "    def add(self, value):\n",
    "        n = len(self.set)\n",
    "        self.set.add(value)\n",
    "        return n != len(self.set)\n",
    "        \n",
    "        \n",
    "    def set_epsilon(self, value=True):\n",
    "        last = self.contains_epsilon\n",
    "        self.contains_epsilon = value\n",
    "        return last != self.contains_epsilon\n",
    "        \n",
    "    def update(self, other):\n",
    "        n = len(self.set)\n",
    "        self.set.update(other.set)\n",
    "        return n != len(self.set)\n",
    "    \n",
    "    def epsilon_update(self, other):\n",
    "        return self.set_epsilon(self.contains_epsilon | other.contains_epsilon)\n",
    "    \n",
    "    def hard_update(self, other):\n",
    "        return self.update(other) | self.epsilon_update(other)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.set) + int(self.contains_epsilon)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '%s-%s' % (str(self.set), self.contains_epsilon)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.set)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, ContainerSet) and self.set == other.set and self.contains_epsilon == other.contains_epsilon\n",
    "\n",
    "# Simplemente para usar la defini\u00f3n del modulo cmp\n",
    "from cmp.utils import ContainerSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First de una forma oracional\n",
    "\n",
    "Recordemos que el conjunto *First* de una forma oracional se define como:\n",
    "- $First(w) = \\{ x \\in V_t $ | $ w \\Rightarrow^* x \\alpha, \\alpha \\in (V_t \\cup V_n)^* \\}$\n",
    "    - $\\cup$ $\\{ \\epsilon  \\}$, si $w \\Rightarrow^* \\epsilon$\n",
    "    - $\\cup$ $\\{  \\}$, en otro caso.\n",
    "    \n",
    "Como vimos en conferencia, es posible computar el conjunto _First_ para los _terminales_, _no terminales_ y _producciones_ de la gram\u00e1tica usando un m\u00e9todo de punto fijo. Los _firsts_ se inicializan vac\u00edos y de forma incremental se van actualizando con la aplicaci\u00f3n de las siguientes reglas:\n",
    "- Si `X` $\\rightarrow$ `W1 | W2 | ... | Wn` entonces por definici\u00f3n, First(X) = $\\cup_i$ First($W_i$).\n",
    "- Si `X` $\\rightarrow \\epsilon$ entonces $\\epsilon \\in$ `First(X)`.\n",
    "- Si `W = xZ` donde `x` es un terminal, entonces trivialmente `First(W) = { x }`.\n",
    "- Si `W = YZ` donde `Y` es un no-terminal y `Z` una forma oracional, entonces `First(Y)` $\\subseteq$ `First(W)`.\n",
    "- Si `W = YZ` y $\\epsilon \\in$ `First(Y)` entonces `First(Z)` $\\subseteq$ `First(W)`.\n",
    "\n",
    "Una vez se termine una iteraci\u00f3n sin que ocurran cambios se puede dar por terminado el calculo de los _firsts_.\n",
    "\n",
    "Implementemos el algoritmo para calcular el _first_ de los s\u00edmbolos y producciones de la gram\u00e1tica en dos fases:\n",
    "- Con el m\u00e9todo `compute_local_first` calcularemos `First(alpha)`, donde `alpha` es una forma oracional, seg\u00fan la versi\u00f3n \"actual\" del conjunto _firsts_ ya computada.\n",
    "- Con el m\u00e9todo `compute_firsts` calcularemos todos los conjuntos _firsts_. Para ello, realizaremos actualizaciones a los conjuntos iniciales seg\u00fan los resultados de aplicar `compute_local_first` en cada producci\u00f3n.\n",
    "\n",
    "#### Primera fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes First(alpha), given First(Vt) and First(Vn) \n",
    "# alpha in (Vt U Vn)*\n",
    "def compute_local_first(firsts, alpha):\n",
    "    first_alpha = ContainerSet()\n",
    "    \n",
    "    try:\n",
    "        alpha_is_epsilon = alpha.IsEpsilon\n",
    "    except:\n",
    "        alpha_is_epsilon = False\n",
    "    \n",
    "    ###################################################\n",
    "    # alpha == epsilon ? First(alpha) = { epsilon }\n",
    "    ###################################################\n",
    "    #                   <CODE_HERE>                   #\n",
    "    ###################################################\n",
    "    \n",
    "    ###################################################\n",
    "    # alpha = X1 ... XN\n",
    "    # First(Xi) subconjunto First(alpha)\n",
    "    # epsilon pertenece a First(X1)...First(Xi) ? First(Xi+1) subconjunto de First(X) y First(alpha)\n",
    "    # epsilon pertenece a First(X1)...First(XN) ? epsilon pertence a First(X) y al First(alpha)\n",
    "    ###################################################\n",
    "    #                   <CODE_HERE>                   #\n",
    "    ###################################################\n",
    "    \n",
    "    # First(alpha)\n",
    "    return first_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segunda fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes First(Vt) U First(Vn) U First(alpha)\n",
    "# P: X -> alpha\n",
    "def compute_firsts(G):\n",
    "    firsts = {}\n",
    "    change = True\n",
    "    \n",
    "    # init First(Vt)\n",
    "    for terminal in G.terminals:\n",
    "        firsts[terminal] = ContainerSet(terminal)\n",
    "        \n",
    "    # init First(Vn)\n",
    "    for nonterminal in G.nonTerminals:\n",
    "        firsts[nonterminal] = ContainerSet()\n",
    "    \n",
    "    while change:\n",
    "        change = False\n",
    "        \n",
    "        # P: X -> alpha\n",
    "        for production in G.Productions:\n",
    "            X = production.Left\n",
    "            alpha = production.Right\n",
    "            \n",
    "            # get current First(X)\n",
    "            first_X = firsts[X]\n",
    "                \n",
    "            # init First(alpha)\n",
    "            try:\n",
    "                first_alpha = firsts[alpha]\n",
    "            except KeyError:\n",
    "                first_alpha = firsts[alpha] = ContainerSet()\n",
    "            \n",
    "            # CurrentFirst(alpha)???\n",
    "            local_first = compute_local_first(firsts, alpha)\n",
    "            \n",
    "            # update First(X) and First(alpha) from CurrentFirst(alpha)\n",
    "            change |= first_alpha.hard_update(local_first)\n",
    "            change |= first_X.hard_update(local_first)\n",
    "                    \n",
    "    # First(Vt) + First(Vt) + First(RightSides)\n",
    "    return firsts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos que el algoritmo est\u00e1 bien implementado. Los conjuntos _First_ resultantes deber\u00edan ser:\n",
    "\n",
    "**Terminales**\n",
    "```\n",
    "+   :  { + }\n",
    "-   :  { - }\n",
    "*   :  { * }\n",
    "/   :  { / }\n",
    "(   :  { ( }\n",
    ")   :  { ) }\n",
    "num :  { num }\n",
    "```\n",
    "\n",
    "**No Terminales**\n",
    "```\n",
    "E  :  { num, ( }\n",
    "T  :  { num, ( }\n",
    "F  :  { num, ( }\n",
    "X  :  { +, -, epsilon }\n",
    "Y  :  { /, *, epsilon }\n",
    "```\n",
    "\n",
    "**Producciones**\n",
    "```\n",
    "T X     :  { num, ( }\n",
    "+ T X   :  { + }\n",
    "- T X   :  { - }\n",
    "epsilon :  { epsilon }\n",
    "F Y     :  { num, ( }\n",
    "* F Y   :  { * }\n",
    "/ F Y   :  { / }\n",
    "num     :  { num }\n",
    "( E )   :  { ( }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.languages import BasicHulk\n",
    "hulk = BasicHulk(G)\n",
    "\n",
    "firsts = compute_firsts(G)\n",
    "assert firsts == hulk.firsts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follows\n",
    "\n",
    "Recordemos que el conjunto _Follow_ de un _no terminal_ se define como:\n",
    "- $Follow(X) = \\{ a \\in V_t \\cup \\{ \\$ \\} $ | $ S\\$ \\Rightarrow^* \\alpha X a \\beta , \\alpha \\in (V_t \\cup V_n)^* \\},  \\beta \\in (V_t \\cup V_n \\cup \\{ \\$ \\})^* \\}$\n",
    "\n",
    "Para calcular los _follows_ de los no terminales procederemos de forma similar a como hicimos con los _firsts_. Aplicaremos un m\u00e9todo de punto fijo seg\u00fan las reglas:\n",
    "- `$` pertenece al `Follow(S)`.\n",
    "- Por definici\u00f3n `epsilon` nunca pertenece al `Follow(X)` para todo `X`.\n",
    "- Si `X` $\\rightarrow$ `WAZ` siendo `W` y `Z` formas oracionales, y `A` un no-terminal cualquiera, entonces `First(Z) - {` $\\epsilon$ `}` $\\subseteq$ `Follow(A)`.\n",
    "- Si `X` $\\rightarrow$ `WAZ` y $\\epsilon \\in$ `First(Z)`, entonces `Follow(X)` $\\subseteq$ `Follow(A)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def compute_follows(G, firsts):\n",
    "    follows = { }\n",
    "    change = True\n",
    "    \n",
    "    local_firsts = {}\n",
    "    \n",
    "    # init Follow(Vn)\n",
    "    for nonterminal in G.nonTerminals:\n",
    "        follows[nonterminal] = ContainerSet()\n",
    "    follows[G.startSymbol] = ContainerSet(G.EOF)\n",
    "    \n",
    "    while change:\n",
    "        change = False\n",
    "        \n",
    "        # P: X -> alpha\n",
    "        for production in G.Productions:\n",
    "            X = production.Left\n",
    "            alpha = production.Right\n",
    "            \n",
    "            follow_X = follows[X]\n",
    "            \n",
    "            ###################################################\n",
    "            # X -> zeta Y beta\n",
    "            # First(beta) - { epsilon } subset of Follow(Y)\n",
    "            # beta ->* epsilon or X -> zeta Y ? Follow(X) subset of Follow(Y)\n",
    "            ###################################################\n",
    "            #                   <CODE_HERE>                   #\n",
    "            ###################################################\n",
    "\n",
    "    # Follow(Vn)\n",
    "    return follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos que el algoritmo est\u00e1 bien implementado. Los conjuntos _Follow_ resultantes deber\u00edan ser:\n",
    "\n",
    "```\n",
    "E :  { ), $ }\n",
    "T :  { +, ), -, $ }\n",
    "F :  { /, +, ), *, -, $ }\n",
    "X :  { ), $ }\n",
    "Y :  { +, ), -, $ }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follows = compute_follows(G, firsts)\n",
    "assert follows == hulk.follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla LL(1)\n",
    "\n",
    "Una vez tenemos todos los conjuntos `First` y `Follow` calculados, construiremos una tabla `T`, donde asociaremos a cada par no-terminal `X` / token `t` una producci\u00f3n (a lo sumo). Dicha producci\u00f3n es la \u00fanica que tiene sentido aplicar si se debe expandir el no-terminal `X` y el token actual es `t`.\n",
    "\n",
    "Las reglas generales para generar esta tabla son las siguientes:\n",
    "\n",
    "1. Si `X` $\\to$ `W` y `t` $\\in V_t$ pertenece al `First(W)` entonces `T[X,t] = X` $\\to$ `W`.\n",
    "2. Si `X` $\\to$ `W` con $\\epsilon \\in$ `First(W)` y `t` pertenece al `Follow(X)` entonces `T[X,t] = X` $\\to$ `W`.\n",
    "\n",
    "Si al aplicar estas reglas, en cada posici\u00f3n `T[X,t]` obtenemos a lo sumo una producci\u00f3n, entonces decimos que una gram\u00e1tica es LL(1). En caso contrario, tenemos al menos un conflicto, pues hay m\u00e1s de una producci\u00f3n que tiene sentido utilizar en alg\u00fan caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parsing_table(G, firsts, follows):\n",
    "    # init parsing table\n",
    "    M = {}\n",
    "    \n",
    "    # P: X -> alpha\n",
    "    for production in G.Productions:\n",
    "        X = production.Left\n",
    "        alpha = production.Right\n",
    "        \n",
    "        ###################################################\n",
    "        # working with symbols on First(alpha) ...\n",
    "        ###################################################\n",
    "        #                   <CODE_HERE>                   #\n",
    "        ###################################################    \n",
    "        \n",
    "        \n",
    "        ###################################################\n",
    "        # working with epsilon...\n",
    "        ###################################################\n",
    "        #                   <CODE_HERE>                   #\n",
    "        ###################################################\n",
    "    \n",
    "    # parsing table is ready!!!\n",
    "    return M            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos que el algoritmo est\u00e1 bien implementado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = build_parsing_table(G, firsts, follows)\n",
    "assert M == hulk.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Descendente No Recursivo\n",
    "\n",
    "Una vez obtenida la tabla LL(1) podemos escribir un algoritmo de parsing descendente no recursivo. La idea general consiste en emplear una pila de s\u00edmbolos, donde iremos construyendo la forma oracional que eventualmente derivar\u00e1 en la cadena a reconocer. Si leemos la pila desde el tope hasta el fondo, en todo momento tendremos una forma oracional que debe generar la parte de la cadena no reconocida.\n",
    "\n",
    "El s\u00edmbolo en el tope de la pila representa el terminal o no-terminal a analizar. En caso de ser un terminal, debe coincidir con el token analizado. En caso de ser un no-terminal, se consulta la tabla LL(1) y se ejecuta la producci\u00f3n correspondiente, insertando en la pila (en orden inverso) la forma oracional en que deriva el no-terminal extra\u00eddo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_predictivo_no_recursivo(G, M=None, firsts=None, follows=None):\n",
    "    \n",
    "    # checking table...\n",
    "    if M is None:\n",
    "        if firsts is None:\n",
    "            firsts = compute_firsts(G)\n",
    "        if follows is None:\n",
    "            follows = compute_follows(G, firsts)\n",
    "        M = build_parsing_table(G, firsts, follows)\n",
    "    \n",
    "    \n",
    "    # parser construction...\n",
    "    def parser(w):\n",
    "        \n",
    "        ###################################################\n",
    "        # w ends with $ (G.EOF)\n",
    "        ###################################################\n",
    "        # init:\n",
    "        ### stack =  ????\n",
    "        ### cursor = ????\n",
    "        ### output = ????\n",
    "        ###################################################\n",
    "        \n",
    "        # parsing w...\n",
    "        while True:\n",
    "            top = stack.pop()\n",
    "            a = w[cursor]\n",
    "            \n",
    "            ###################################################\n",
    "            #                   <CODE_HERE>                   #\n",
    "            ###################################################\n",
    "\n",
    "        # left parse is ready!!!\n",
    "        return output\n",
    "    \n",
    "    # parser is ready!!!\n",
    "    return parser\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos que el algoritmo est\u00e1 bien implementado. El parse izquierdo para la cadena `\"n * n * n + n * n + n + n $\"` es:\n",
    "```\n",
    "E -> T X\n",
    "T -> F Y\n",
    "F -> num\n",
    "Y -> * F Y\n",
    "F -> num\n",
    "Y -> * F Y\n",
    "F -> num\n",
    "Y -> e\n",
    "X -> + T X\n",
    "T -> F Y\n",
    "F -> num\n",
    "Y -> * F Y\n",
    "F -> num\n",
    "Y -> e\n",
    "X -> + T X\n",
    "T -> F Y\n",
    "F -> num\n",
    "Y -> e\n",
    "X -> + T X\n",
    "T -> F Y\n",
    "F -> num\n",
    "Y -> e\n",
    "X -> e\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = metodo_predictivo_no_recursivo(G, M)\n",
    "left_parse = parser([num, star, num, star, num, plus, num, star, num, plus, num, plus, num, G.EOF])\n",
    "\n",
    "assert left_parse == [ \n",
    "   Production(E, Sentence(T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, Sentence(star, F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, Sentence(star, F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, Sentence(plus, T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, Sentence(star, F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, Sentence(plus, T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, Sentence(plus, T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, G.Epsilon),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos\n",
    "\n",
    "Probemos el generador de parser implementado con otras gram\u00e1ticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gram\u00e1tica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Grammar()\n",
    "S = G.NonTerminal('S', True)\n",
    "A,B = G.NonTerminals('A B')\n",
    "a,b = G.Terminals('a b')\n",
    "\n",
    "S %= A + B\n",
    "A %= a + A | a\n",
    "B %= b + B | b\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "firsts = compute_firsts(G)\n",
    "pprint(firsts)\n",
    "\n",
    "# print(inspect(firsts))\n",
    "assert firsts == {\n",
    "   a: ContainerSet(a , contains_epsilon=False),\n",
    "   b: ContainerSet(b , contains_epsilon=False),\n",
    "   S: ContainerSet(a , contains_epsilon=False),\n",
    "   A: ContainerSet(a , contains_epsilon=False),\n",
    "   B: ContainerSet(b , contains_epsilon=False),\n",
    "   Sentence(A, B): ContainerSet(a , contains_epsilon=False),\n",
    "   Sentence(a, A): ContainerSet(a , contains_epsilon=False),\n",
    "   Sentence(a): ContainerSet(a , contains_epsilon=False),\n",
    "   Sentence(b, B): ContainerSet(b , contains_epsilon=False),\n",
    "   Sentence(b): ContainerSet(b , contains_epsilon=False) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follows = compute_follows(G, firsts)\n",
    "pprint(follows)\n",
    "\n",
    "# print(inspect(follows))\n",
    "assert follows == {\n",
    "   S: ContainerSet(G.EOF , contains_epsilon=False),\n",
    "   A: ContainerSet(b , contains_epsilon=False),\n",
    "   B: ContainerSet(G.EOF , contains_epsilon=False) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = build_parsing_table(G, firsts, follows)\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gramatica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Grammar()\n",
    "S = G.NonTerminal('S', True)\n",
    "A,B,C = G.NonTerminals('A B C')\n",
    "a,b,c,d,f = G.Terminals('a b c d f')\n",
    "\n",
    "S %= a + A | B + C | f + B + f\n",
    "A %= a + A | G.Epsilon\n",
    "B %= b + B | G.Epsilon\n",
    "C %= c + C | d\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firsts = compute_firsts(G)\n",
    "pprint(firsts)\n",
    "\n",
    "# print(inspect(firsts))\n",
    "assert firsts == {\n",
    "   a: ContainerSet(a , contains_epsilon=False),\n",
    "   b: ContainerSet(b , contains_epsilon=False),\n",
    "   c: ContainerSet(c , contains_epsilon=False),\n",
    "   d: ContainerSet(d , contains_epsilon=False),\n",
    "   f: ContainerSet(f , contains_epsilon=False),\n",
    "   S: ContainerSet(d, a, f, c, b , contains_epsilon=False),\n",
    "   A: ContainerSet(a , contains_epsilon=True),\n",
    "   B: ContainerSet(b , contains_epsilon=True),\n",
    "   C: ContainerSet(c, d , contains_epsilon=False),\n",
    "   Sentence(a, A): ContainerSet(a , contains_epsilon=False),\n",
    "   Sentence(B, C): ContainerSet(d, c, b , contains_epsilon=False),\n",
    "   Sentence(f, B, f): ContainerSet(f , contains_epsilon=False),\n",
    "   G.Epsilon: ContainerSet( contains_epsilon=True),\n",
    "   Sentence(b, B): ContainerSet(b , contains_epsilon=False),\n",
    "   Sentence(c, C): ContainerSet(c , contains_epsilon=False),\n",
    "   Sentence(d): ContainerSet(d , contains_epsilon=False) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follows = compute_follows(G, firsts)\n",
    "pprint(follows)\n",
    "\n",
    "# print(inspect(follows))\n",
    "assert follows == {\n",
    "   S: ContainerSet(G.EOF , contains_epsilon=False),\n",
    "   A: ContainerSet(G.EOF , contains_epsilon=False),\n",
    "   B: ContainerSet(d, f, c , contains_epsilon=False),\n",
    "   C: ContainerSet(G.EOF , contains_epsilon=False) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = build_parsing_table(G, firsts, follows)\n",
    "pprint(M)\n",
    "\n",
    "# print(inspect(M))\n",
    "assert M == {\n",
    "   ( S, a, ): [ Production(S, Sentence(a, A)), ],\n",
    "   ( S, c, ): [ Production(S, Sentence(B, C)), ],\n",
    "   ( S, b, ): [ Production(S, Sentence(B, C)), ],\n",
    "   ( S, d, ): [ Production(S, Sentence(B, C)), ],\n",
    "   ( S, f, ): [ Production(S, Sentence(f, B, f)), ],\n",
    "   ( A, a, ): [ Production(A, Sentence(a, A)), ],\n",
    "   ( A, G.EOF, ): [ Production(A, G.Epsilon), ],\n",
    "   ( B, b, ): [ Production(B, Sentence(b, B)), ],\n",
    "   ( B, c, ): [ Production(B, G.Epsilon), ],\n",
    "   ( B, f, ): [ Production(B, G.Epsilon), ],\n",
    "   ( B, d, ): [ Production(B, G.Epsilon), ],\n",
    "   ( C, c, ): [ Production(C, Sentence(c, C)), ],\n",
    "   ( C, d, ): [ Production(C, Sentence(d)), ] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = metodo_predictivo_no_recursivo(G, M)\n",
    "\n",
    "left_parse = parser([b, b, d, G.EOF])\n",
    "pprint(left_parse)\n",
    "\n",
    "# print(inspect(left_parse))\n",
    "assert left_parse == [ \n",
    "   Production(S, Sentence(B, C)),\n",
    "   Production(B, Sentence(b, B)),\n",
    "   Production(B, Sentence(b, B)),\n",
    "   Production(B, G.Epsilon),\n",
    "   Production(C, Sentence(d)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstrucci\u00f3n del \u00e1rbol de derivaci\u00f3n y evaluaci\u00f3n\n",
    "- Implemente un algoritmo b\u00e1sico de tokenizaci\u00f3n para a partir de un `string` obtener la sequencia de tokens correspondiente. Note que los s\u00edmbolos terminales de la gram\u00e1tica coincide con los \"tipos\" de tokens, pero no contienen el lexemas.\n",
    "- Reconstruya el \u00e1rbol de derivaci\u00f3n a partir del parse izquierdo que devuelve el parser.\n",
    "- Utilice el \u00e1rbol de derivaci\u00f3n para evaluar la expresi\u00f3n. Note que la estructura de la gram\u00e1tica causa que los operadores (+, -, \\*, /) asocien hacia la derecha, lo cual conlleva problemas si se eval\u00faa recursivamente sin considerar tal caracter\u00edstica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}