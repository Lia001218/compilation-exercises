{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Práctica #3 (Compilación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminares\n",
    "\n",
    "El objetivo de esta clase es implementar un **generador automático de parsers LL(1)**. Tal generador recibiría como entrada la especificación de una gramática. Siguiendo esta idea, primeramente deberíamos ser capaces de representar de forma clara y cómoda tal \"especificación\" de la gramática.\n",
    "\n",
    "A continuación se describen un número de clases que nos serán útiles para construir, de forma concisa, una gramática como un objeto de **Python**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Símbolos\n",
    "\n",
    "Modelaremos los **símbolos** del lenguaje con la clase `Symbol`. Esta clase funcionará como base para la definición de terminales y no terminales. Entre las funcionalidades básicas de los símbolos tenemos que:\n",
    "- Pueden ser agrupados con el operador `+` para formar oraciones.\n",
    "- Podemos conocer si representa la cadena especial **epsilon** a través de la propiedad `IsEpsilon` que poseen todas las instancias.\n",
    "- Podemos acceder a la gramática en la que se definió a través del campo `Grammar` de cada instancia.\n",
    "- Podemos consultar la notación del símbolo a través del campo `Name` de cada instancia.\n",
    "\n",
    "Los símbolos no deben ser instanciados directamente (ni sus descendiente) con la aplicación de su constructor. En su lugar, utilizaremos una sintaxis descrita más adelante para definirlos junto a la especificación de la gramática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Terminales\n",
    "\n",
    "Los símbolos **no terminales** los modelaremos con la clase `NonTerminal`. Dicha clase extiende la clase `Symbol` para:\n",
    "- Añadir noción de las producción que tiene al no terminal como cabecera. Estas pueden ser conocidas a través del campo `productions` de cada instancia.\n",
    "- Permitir añadir producciones para ese no terminal a través del operador `%=`.\n",
    "- Incluir propiedades `IsNonTerminal` - `IsTerminal` que devolveran `True` - `False` respectivamente.\n",
    "\n",
    "Los no terminales no deben ser instanciados directamente con la aplicación de su constructor. En su lugar, se presentan las siguientes facilidades para definir no terminales a partir de una instancia `G` de `Grammar`:\n",
    "- Para definir un único no terminal:\n",
    "    ```python\n",
    "    non_terminal_var = G.NonTerminal('<non-terminal-name>')\n",
    "    # non_terminal_var    <--- variable en la que guardaremos la referencia al no terminal.\n",
    "    # <non-terminal-name> <--- nombre concreto del no terminal.\n",
    "    ```\n",
    "- Para definir el símbolo distingido:\n",
    "    ```python\n",
    "    start_var = G.NonTerminal('<start-name>', True)\n",
    "    # start_var    <--- variable en la que guardaremos la referencia símbolo distinguido.\n",
    "    # <start-name> <--- nombre concreto del símbolo distinguido.\n",
    "    ```\n",
    "- Para definir múltiples no terminales:\n",
    "    ```python\n",
    "    var1, var2, ..., varN = G.NonTerminals('<name1> <name2> ... <nameN>')\n",
    "    # var1, var2, ..., varN    <--- variables en las que guardaremos las referencias a los no terminales.\n",
    "    # <name1> <name2> ... <nameN> <--- nombres concretos del no terminales (separados por espacios).\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import NonTerminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminales\n",
    "\n",
    "Los símbolos **terminales** los modelaremos con la clase `Terminal`. Dicha clase extiende la clase `Symbol` para:\n",
    "- Incluir propiedades `IsNonTerminal` - `IsTerminal` que devolveran `True` - `False` respectivamente.\n",
    "\n",
    "Los terminales no deben ser instanciados directamente con la aplicación de su constructor. En su lugar, se presentan las siguientes facilidades para definir no terminales a partir de una instancia `G` de `Grammar`:\n",
    "- Para definir un único terminal:\n",
    "    ```python\n",
    "    terminal_var = G.Terminal('<terminal-name>')\n",
    "    # terminal_var    <--- variable en la que guardaremos la referencia al terminal.\n",
    "    # <terminal-name> <--- nombre concreto del terminal.\n",
    "    ```\n",
    "- Para definir múltiples terminales:\n",
    "    ```python\n",
    "    var1, var2, ..., varN = G.Terminals('<name1> <name2> ... <nameN>')\n",
    "    # var1, var2, ..., varN    <--- variables en las que guardaremos las referencias a los terminales.\n",
    "    # <name1> <name2> ... <nameN> <--- nombres concretos del terminales (separados por espacios).\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fin de Cadena (EOF, *$*)\n",
    "Modelaremos el símbolo de fin de cadena con la clase `EOF`. Dicha clase extiende la clases `Terminal` para heradar su comportamiento.\n",
    "\n",
    "La clase `EOF` no deberá ser instanciada directamente con la aplicación de su constructor. En su lugar, una instancia concreta para determinada gramática `G` de `Grammar` se construirá automáticamente y será accesible a través de `G.EOF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oraciones y Formas Oracionales\n",
    "\n",
    "Modelaremos los **oraciones** y **formas oracionales** del lenguaje con la clase `Sentence`. Esta clase funcionará como una colección de terminales y no terminales. Entre las funcionalidades básicas que provee tenemos que nos :\n",
    "- Permite acceder a los símbolos que componen la oración a través del campo `_symbols` de cada instancia.\n",
    "- Permite conocer si la oración es completamente vacía a través de la propiedad `IsEpsilon`.\n",
    "- Permite obtener la concatenación con un símbolo u otra oración aplicando el operador `+`.\n",
    "- Permite conocer la longitud de la oración (cantidad de símbolos que la componen) utilizando la función *build-in* de python `len(...)`.\n",
    "\n",
    "Las oraciones pueden ser agrupadas usando el operador `|`. Esto nos será conveniente para definir las producciones las producciones que tengan la misma cabeza (no terminal en la parte izquierda) en una única sentencia. El grupo de oraciones se maneja con la clase `SentenceList`.\n",
    "\n",
    "No se deben crear instancias de `Sentence` y `SentenceList` directamente con la aplicación de los respectivos constructores. En su lugar, usaremos el operador `+` entre símbolos para formar las oraciones, y el operador `|` entre oraciones para agruparlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Sentence, SentenceList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon\n",
    "\n",
    "Modelaremos tanto la **cadena vacía** como el símbolo que la representa: **epsilon** ($\\epsilon$), en la misma clase: `Epsilon`. Dicha clase extiende las clases `Terminal` y `Sentence` por lo que ser comporta como ambas. Sobreescribe la implementación del método `IsEpsilon` para indicar que en efecto toda instancia de la clase reprensenta **epsilon**.\n",
    "\n",
    "La clase `Epsilon` no deberá ser instanciada directamente con la aplicación de su constructor. En su lugar, una instancia concreta para determinada gramática `G` de `Grammar` se construirá automáticamente y será accesible a través de `G.Epsilon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producciones\n",
    "\n",
    "Modelaremos las **producciones** con la clase `Production`. Las funcionalidades básicas con que contamos son:\n",
    "- Poder acceder la cabecera (parte izquierda) y cuerpo (parte derecha) de cada producción a través de los campos `Left` y `Right` respectivamente.\n",
    "- Consultar si la producción es de la forma $X \\rightarrow \\epsilon$ a través de la propiedad `IsEpsilon`.\n",
    "- Desempaquetar la producción en cabecera y cuerpo usando asignaciones: `left, right = production`.\n",
    "\n",
    "Las producciones no deben ser instanciadas directamente con la aplicación de su constructor. En su lugar, se presentan las siguientes facilidades para formar producciones a partir de una instancia `G` de `Grammar` y un grupo de terminales y no terminales:\n",
    "- Para definir una producción de la forma $E \\rightarrow E + T$:\n",
    "    ```python\n",
    "    E %= E + plus + T\n",
    "    ```\n",
    "- Para definir múltiples producciones de la misma cabecera en una única sentencia ($E \\rightarrow$ $E + T$ | $E - T$ | $T$):\n",
    "    ```python\n",
    "    E %= E + plus + T | E + minus + T | T\n",
    "    ```\n",
    "- Para usar *epsilon* en una producción (ejemplo $S \\rightarrow$ $aS$ | $\\epsilon$) haríamos:\n",
    "    ```python\n",
    "    S %= S + a | G.Epsilon\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gramática\n",
    "\n",
    "Modelaremos las **gramáticas** con la clase `Grammar`. Las funcionalidades básicas con que contamos son:\n",
    "- Definir los símbolos _terminales_ y _no terminales_ de la gramática en cuestión a través de los métodos `Terminal` y `Terminals` para los primeros, y `NonTerminal` y `NonTerminals` para los segundos.\n",
    "- Definir las producciones de la gramática a partir de la aplicación del operador `%=` entre no terminales y oraciones (estas a su vez formadas por la concatenación de símbolos).\n",
    "- Acceder a **todas** las _producciones_ a través del campo `Productions` de cada instancia.\n",
    "- Acceder a **todos** los _terminales_ y _no terminales_ a través de los campos `terminals` y `nonTerminals` respectivamente.\n",
    "- Acceder al _símbolo distinguido_, _epsilon_ y _fin de cadena_ a través de los campos `startSymbol`, `Epsilon` y `EOF` respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo: Gramática de HULK\n",
    "\n",
    "A continuación de muestra cómo especificar la gramática LL(1) para `HULK` vista en conferencias:\n",
    "\n",
    "$ E \\rightarrow$ $TX$  \n",
    "$ X \\rightarrow$ $+TX$ | $-TX$ | $\\epsilon$  \n",
    "$ T \\rightarrow$ $FY$  \n",
    "$ Y \\rightarrow$ $*FY$ | $/FY$ | $\\epsilon$  \n",
    "$ F \\rightarrow$ $( E )$ | num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Terminals:\n",
      "\tE, T, F, X, Y\n",
      "Terminals:\n",
      "\t+, -, *, /, (, ), num\n",
      "Productions:\n",
      "\t[E -> T X, X -> + T X, X -> - T X, X -> e, T -> F Y, Y -> * F Y, Y -> / F Y, Y -> e, F -> num, F -> ( E )]\n"
     ]
    }
   ],
   "source": [
    "from cmp.utils import pprint, inspect\n",
    "\n",
    "G = Grammar()\n",
    "E = G.NonTerminal('E', True)\n",
    "T,F,X,Y = G.NonTerminals('T F X Y')\n",
    "plus, minus, star, div, opar, cpar, num = G.Terminals('+ - * / ( ) num')\n",
    "\n",
    "E %= T + X\n",
    "X %= plus + T + X | minus + T + X | G.Epsilon\n",
    "T %= F + Y\n",
    "Y %= star + F + Y | div + F + Y | G.Epsilon\n",
    "F %= num | opar + E + cpar\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generador de parsers LL(1)\n",
    "\n",
    "Pasemos a implementar un generador de parsers LL(1). Para ello será necesario implementar un algoritmo que compute el conjunto _First_ de los símbolos terminales, no terminales y producciones. Además, implementaremos un algoritmo para computar el _Follow_ de todos los no terminales de la gramática.\n",
    "\n",
    "Una vez podamos calcular dichos conjuntos, construiremos una tabla con $|V_N|$ filas y $|V_t| + 1$ columnas, que representará la unidad de control del parser. La celda $(i,j)$ de la tabla contiene la producción a aplicar si al \"tratar\" de parsear el _i-ésimo_ no terminal, el cabezal queda apuntando al símbolo asociado a la columna _j_ (es un terminal o _$_). Aplicar una producción se reduce a consumir terminales y tratar de parsear no terminales, según van apareciendo en la parte derecha de la producción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de símbolos\n",
    "\n",
    "Resulta conveniente manejar la pertenencia o no de *epsilon* a un conjunto como un caso extremo. Para ello usaremos la clase `ContainerSet` implementada a continuación.\n",
    "- La clase funciona como un conjunto de símbolos.\n",
    "- Permite consulta la pertenencia de _epsilon_ al conjunto.\n",
    "- Las operaciones que modifican el conjunto devuelven si hubo _cambio_ o _no_.\n",
    "- El conjunto puede ser actualizado con la adición de elementos individuales, `add(...)`, o a partir de otro conjunto,`update(...)` y `hard_update(...)`.\n",
    "- La actualización _sin epsilon (1)_, _con epsilon (2)_ y de _solo epsilon (3)_, ocurre a través de `update(...)`, `hard_update(...)` y `epsilon_update(...)` respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContainerSet:\n",
    "    def __init__(self, *values, contains_epsilon=False):\n",
    "        self.set = set(values)\n",
    "        self.contains_epsilon = contains_epsilon\n",
    "        \n",
    "    def add(self, value):\n",
    "        n = len(self.set)\n",
    "        self.set.add(value)\n",
    "        return n != len(self.set)\n",
    "        \n",
    "        \n",
    "    def set_epsilon(self, value=True):\n",
    "        last = self.contains_epsilon\n",
    "        self.contains_epsilon = value\n",
    "        return last != self.contains_epsilon\n",
    "        \n",
    "    def update(self, other):\n",
    "        n = len(self.set)\n",
    "        self.set.update(other.set)\n",
    "        return n != len(self.set)\n",
    "    \n",
    "    def epsilon_update(self, other):\n",
    "        return self.set_epsilon(self.contains_epsilon | other.contains_epsilon)\n",
    "    \n",
    "    def hard_update(self, other):\n",
    "        return self.update(other) | self.epsilon_update(other)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.set) + int(self.contains_epsilon)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '%s-%s' % (str(self.set), self.contains_epsilon)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.set)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, ContainerSet) and self.set == other.set and self.contains_epsilon == other.contains_epsilon\n",
    "\n",
    "# Simplemente para usar la definión del modulo cmp\n",
    "from cmp.utils import ContainerSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First de una forma oracional\n",
    "\n",
    "Recordemos que el conjunto *First* de una forma oracional se define como:\n",
    "- $First(w) = \\{ x \\in V_t $ | $ w \\Rightarrow^* x \\alpha, \\alpha \\in (V_t \\cup V_n)^* \\}$\n",
    "    - $\\cup$ $\\{ \\epsilon  \\}$, si $w \\Rightarrow^* \\epsilon$\n",
    "    - $\\cup$ $\\{  \\}$, en otro caso.\n",
    "    \n",
    "Como vimos en conferencia, es posible computar el conjunto _First_ para los _terminales_, _no terminales_ y _producciones_ de la gramática usando un método de punto fijo. Los _firsts_ se inicializan vacíos y de forma incremental se van actualizando con la aplicación de las siguientes reglas:\n",
    "- Si `X` $\\rightarrow$ `W1 | W2 | ... | Wn` entonces por definición, First(X) = $\\cup_i$ First($W_i$).\n",
    "- Si `X` $\\rightarrow \\epsilon$ entonces $\\epsilon \\in$ `First(X)`.\n",
    "- Si `W = xZ` donde `x` es un terminal, entonces trivialmente `First(W) = { x }`.\n",
    "- Si `W = YZ` donde `Y` es un no-terminal y `Z` una forma oracional, entonces `First(Y)` $\\subseteq$ `First(W)`.\n",
    "- Si `W = YZ` y $\\epsilon \\in$ `First(Y)` entonces `First(Z)` $\\subseteq$ `First(W)`.\n",
    "\n",
    "Una vez se termine una iteración sin que ocurran cambios se puede dar por terminado el calculo de los _firsts_.\n",
    "\n",
    "Implementemos el algoritmo para calcular el _first_ de los símbolos y producciones de la gramática en dos fases:\n",
    "- Con el método `compute_local_first` calcularemos `First(alpha)`, donde `alpha` es una forma oracional, según la versión \"actual\" del conjunto _firsts_ ya computada.\n",
    "- Con el método `compute_firsts` calcularemos todos los conjuntos _firsts_. Para ello, realizaremos actualizaciones a los conjuntos iniciales según los resultados de aplicar `compute_local_first` en cada producción.\n",
    "\n",
    "#### Primera fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes First(alpha), given First(Vt) and First(Vn) \n",
    "# alpha in (Vt U Vn)*\n",
    "from cmath import e\n",
    "\n",
    "\n",
    "def compute_local_first(firsts, alpha):\n",
    "    first_alpha = ContainerSet()\n",
    "    \n",
    "    try:\n",
    "        alpha_is_epsilon = alpha.IsEpsilon\n",
    "    except:\n",
    "        alpha_is_epsilon = False\n",
    "    \n",
    "    ###################################################\n",
    "    # alpha == epsilon ? First(alpha) = { epsilon }\n",
    "    ###################################################\n",
    "    if(alpha_is_epsilon):\n",
    "        first_alpha.set_epsilon(True)\n",
    "        return first_alpha\n",
    "    ###################################################\n",
    "    \n",
    "    ###################################################\n",
    "    # alpha = X1 ... XN\n",
    "    # First(Xi) subconjunto First(alpha)\n",
    "    # epsilon pertenece a First(X1)...First(Xi) ? First(Xi+1) subconjunto de First(X) y First(alpha)\n",
    "    # epsilon pertenece a First(X1)...First(XN) ? epsilon pertence a First(X) y al First(alpha)\n",
    "    ###################################################\n",
    "    for symbol in alpha:\n",
    "        first_symbol = firsts[symbol]\n",
    "        first_alpha.update(first_symbol)\n",
    "        if(not first_symbol.contains_epsilon):\n",
    "            break\n",
    "            \n",
    "    ###################################################\n",
    "    \n",
    "    # First(alpha)\n",
    "    return first_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segunda fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes First(Vt) U First(Vn) U First(alpha)\n",
    "# P: X -> alpha\n",
    "def compute_firsts(G):\n",
    "    firsts = {}\n",
    "    change = True\n",
    "    \n",
    "    # init First(Vt)\n",
    "    # Each terminal has a First set with only itself\n",
    "    for terminal in G.terminals:\n",
    "        firsts[terminal] = ContainerSet(terminal)\n",
    "    \n",
    "    # init First(Vn)\n",
    "    # Each non-terminal is initialized with an empty set\n",
    "    for nonterminal in G.nonTerminals:\n",
    "        firsts[nonterminal] = ContainerSet()\n",
    "    \n",
    "    while change:\n",
    "        change = False\n",
    "        \n",
    "        # P: X -> alpha\n",
    "        for production in G.Productions:\n",
    "            X = production.Left\n",
    "            alpha = production.Right\n",
    "            \n",
    "            # get current First(X)\n",
    "            first_X = firsts[X]\n",
    "                \n",
    "            # init First(alpha)\n",
    "            try:\n",
    "                first_alpha = firsts[alpha]\n",
    "            except KeyError:\n",
    "                first_alpha = firsts[alpha] = ContainerSet()\n",
    "            \n",
    "            # CurrentFirst(alpha)???\n",
    "            local_first = compute_local_first(firsts, alpha)\n",
    "            # update First(X) and First(alpha) from CurrentFirst(alpha)\n",
    "            change |= first_alpha.hard_update(local_first)\n",
    "            change |= first_X.hard_update(local_first)\n",
    "                    \n",
    "    # First(Vt) + First(Vt) + First(RightSides)\n",
    "    return firsts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos que el algoritmo está bien implementado. Los conjuntos _First_ resultantes deberían ser:\n",
    "\n",
    "**Terminales**\n",
    "```\n",
    "+   :  { + }\n",
    "-   :  { - }\n",
    "*   :  { * }\n",
    "/   :  { / }\n",
    "(   :  { ( }\n",
    ")   :  { ) }\n",
    "num :  { num }\n",
    "```\n",
    "\n",
    "**No Terminales**\n",
    "```\n",
    "E  :  { num, ( }\n",
    "T  :  { num, ( }\n",
    "F  :  { num, ( }\n",
    "X  :  { +, -, epsilon }\n",
    "Y  :  { /, *, epsilon }\n",
    "```\n",
    "\n",
    "**Producciones**\n",
    "```\n",
    "T X     :  { num, ( }\n",
    "+ T X   :  { + }\n",
    "- T X   :  { - }\n",
    "epsilon :  { epsilon }\n",
    "F Y     :  { num, ( }\n",
    "* F Y   :  { * }\n",
    "/ F Y   :  { / }\n",
    "num     :  { num }\n",
    "( E )   :  { ( }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+  --->  {'+'}-False\n",
      "-  --->  {'-'}-False\n",
      "*  --->  {'*'}-False\n",
      "/  --->  {'/'}-False\n",
      "(  --->  {'('}-False\n",
      ")  --->  {')'}-False\n",
      "num  --->  {'num'}-False\n",
      "E  --->  {'num', '('}-False\n",
      "T  --->  {'num', '('}-False\n",
      "F  --->  {'num', '('}-False\n",
      "X  --->  {'-', '+'}-True\n",
      "Y  --->  {'*', '/'}-True\n",
      "T X  --->  {'num', '('}-False\n",
      "+ T X  --->  {'+'}-False\n",
      "- T X  --->  {'-'}-False\n",
      "e  --->  set()-True\n",
      "F Y  --->  {'num', '('}-False\n",
      "* F Y  --->  {'*'}-False\n",
      "/ F Y  --->  {'/'}-False\n",
      "num  --->  {'num'}-False\n",
      "( E )  --->  {'('}-False\n"
     ]
    }
   ],
   "source": [
    "from cmp.languages import BasicHulk\n",
    "hulk = BasicHulk(G)\n",
    "\n",
    "firsts = compute_firsts(G)\n",
    "pprint(firsts)\n",
    "assert firsts == hulk.firsts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follows\n",
    "\n",
    "Recordemos que el conjunto _Follow_ de un _no terminal_ se define como:\n",
    "- $Follow(X) = \\{ a \\in V_t \\cup \\{ \\$ \\} $ | $ S\\$ \\Rightarrow^* \\alpha X a \\beta , \\alpha \\in (V_t \\cup V_n)^* \\},  \\beta \\in (V_t \\cup V_n \\cup \\{ \\$ \\})^* \\}$\n",
    "\n",
    "Para calcular los _follows_ de los no terminales procederemos de forma similar a como hicimos con los _firsts_. Aplicaremos un método de punto fijo según las reglas:\n",
    "- `$` pertenece al `Follow(S)`.\n",
    "- Por definición `epsilon` nunca pertenece al `Follow(X)` para todo `X`.\n",
    "- Si `X` $\\rightarrow$ `WAZ` siendo `W` y `Z` formas oracionales, y `A` un no-terminal cualquiera, entonces `First(Z) - {` $\\epsilon$ `}` $\\subseteq$ `Follow(A)`.\n",
    "- Si `X` $\\rightarrow$ `WAZ` y $\\epsilon \\in$ `First(Z)`, entonces `Follow(X)` $\\subseteq$ `Follow(A)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_follows(G, firsts):\n",
    "    follows = { }\n",
    "    change = True\n",
    "\n",
    "    local_firsts = {}\n",
    "    \n",
    "    # init Follow(Vn)\n",
    "    # Each non-terminal is initialized with an empty set\n",
    "    for nonterminal in G.nonTerminals:\n",
    "        follows[nonterminal] = ContainerSet()\n",
    "    # init Follow(S)\n",
    "    follows[G.startSymbol] = ContainerSet(G.EOF)\n",
    "\n",
    "    while change:\n",
    "        change = False\n",
    "        \n",
    "        # P: X -> alpha\n",
    "        for production in G.Productions:\n",
    "            X = production.Left\n",
    "            alpha = production.Right\n",
    "            \n",
    "            follow_X = follows[X]\n",
    "            \n",
    "            ###################################################\n",
    "            # X -> zeta Y beta\n",
    "            # First(beta) - { epsilon } subset of Follow(Y)\n",
    "            # beta ->* epsilon or X -> zeta Y ? Follow(X) subset of Follow(Y)\n",
    "            ###################################################\n",
    "            for i, symbol in enumerate(alpha):\n",
    "                if(symbol.IsNonTerminal):\n",
    "                    change |= follows[symbol].update(follow_X)\n",
    "                    if( i + 1 < len(alpha)):\n",
    "                        beta = alpha[i+1:]\n",
    "                        for symbol1 in beta :\n",
    "                            if(symbol1.IsNonTerminal):\n",
    "                                try:\n",
    "                                    local_first = local_firsts[symbol1]\n",
    "                                except KeyError:\n",
    "                                    local_first = local_firsts[symbol1] = firsts[symbol1]\n",
    "\n",
    "                                print(local_first)\n",
    "                                print(symbol , follows[symbol])\n",
    "                                change |= follows[symbol].update(local_first)\n",
    "                                from itertools import islice\n",
    "from pprint import pp\n",
    "from random import betavariate\n",
    "\n",
    "def compute_follows(G, firsts):\n",
    "    follows = { }\n",
    "    change = True\n",
    "\n",
    "    local_firsts = {}\n",
    "    \n",
    "    # init Follow(Vn)\n",
    "    # Each non-terminal is initialized with an empty set\n",
    "    for nonterminal in G.nonTerminals:\n",
    "        follows[nonterminal] = ContainerSet()\n",
    "    # init Follow(S)\n",
    "    follows[G.startSymbol] = ContainerSet(G.EOF)\n",
    "\n",
    "    while change:\n",
    "        change = False\n",
    "        \n",
    "        # P: X -> alpha\n",
    "        for production in G.Productions:\n",
    "            X = production.Left\n",
    "            alpha = production.Right\n",
    "            \n",
    "            follow_X = follows[X]\n",
    "            \n",
    "            ###################################################\n",
    "            # X -> zeta Y beta\n",
    "            # First(beta) - { epsilon } subset of Follow(Y)\n",
    "            # beta ->* epsilon or X -> zeta Y ? Follow(X) subset of Follow(Y)\n",
    "            ###################################################\n",
    "            for i, symbol in enumerate(alpha):\n",
    "                if(symbol.IsNonTerminal):\n",
    "                    change |= follows[symbol].update(follow_X)\n",
    "                    if( i + 1 < len(alpha)):\n",
    "                        beta = alpha[i+1:]\n",
    "                        for symbol1 in beta :\n",
    "                            if(symbol1.IsNonTerminal):\n",
    "                                try:\n",
    "                                    local_first = local_firsts[symbol1]\n",
    "                                except KeyError:\n",
    "                                    local_first = local_firsts[symbol1] = firsts[symbol1]\n",
    "\n",
    "                                print(local_first)\n",
    "                                print(symbol , follows[symbol])\n",
    "                                change |= follows[symbol].update(local_first)\n",
    "                                from itertools import islice\n",
    "from pprint import pp\n",
    "from random import betavariate\n",
    "\n",
    "def compute_follows(G, firsts):\n",
    "    follows = { }\n",
    "    change = True\n",
    "\n",
    "    local_firsts = {}\n",
    "    \n",
    "    # init Follow(Vn)\n",
    "    # Each non-terminal is initialized with an empty set\n",
    "    for nonterminal in G.nonTerminals:\n",
    "        follows[nonterminal] = ContainerSet()\n",
    "    # init Follow(S)\n",
    "    follows[G.startSymbol] = ContainerSet(G.EOF)\n",
    "\n",
    "    while change:\n",
    "        change = False\n",
    "        \n",
    "        # P: X -> alpha\n",
    "        for production in G.Productions:\n",
    "            X = production.Left\n",
    "            alpha = production.Right\n",
    "        \n",
    "            \n",
    "            follow_X = follows[X]\n",
    "            \n",
    "            ###################################################\n",
    "            # X -> zeta Y beta\n",
    "            # First(beta) - { epsilon } subset of Follow(Y)\n",
    "            # beta ->* epsilon or X -> zeta Y ? Follow(X) subset of Follow(Y)\n",
    "            ###################################################\n",
    "            for i, symbol in enumerate(alpha):\n",
    "                if(symbol.IsTerminal):\n",
    "                    continue\n",
    "                \n",
    "                if(symbol.IsNonTerminal):\n",
    "                    if( i + 1 < len(alpha)):\n",
    "                        \n",
    "                        beta = alpha[i+1:]\n",
    "                        for symbol1 in beta :\n",
    "\n",
    "                            try:\n",
    "                                local_first = local_firsts[symbol1]\n",
    "                            except KeyError:\n",
    "                                local_first = local_firsts[symbol1] = firsts[symbol1]\n",
    "                           \n",
    "                               \n",
    "                            change |= follows[symbol].update(local_first)\n",
    "                            if(local_first.contains_epsilon):\n",
    "                                change |= follows[symbol].update(follow_X)\n",
    "                    else: \n",
    "                        change |= follows[symbol].update(follow_X)\n",
    "                            \n",
    "            ###################################################\n",
    "\n",
    "    # Follow(Vn)\n",
    "\n",
    "    return follows\n",
    "                                \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos que el algoritmo está bien implementado. Los conjuntos _Follow_ resultantes deberían ser:\n",
    "\n",
    "```\n",
    "E :  { ), $ }\n",
    "T :  { +, ), -, $ }\n",
    "F :  { /, +, ), *, -, $ }\n",
    "X :  { ), $ }\n",
    "Y :  { +, ), -, $ }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E  --->  {')', '$'}-False\n",
      "T  --->  {'+', ')', '$', '-'}-False\n",
      "F  --->  {')', '/', '+', '$', '-', '*'}-False\n",
      "X  --->  {')', '$'}-False\n",
      "Y  --->  {'+', ')', '$', '-'}-False\n"
     ]
    }
   ],
   "source": [
    "follows = compute_follows(G, firsts)\n",
    "pprint(follows)\n",
    "assert follows == hulk.follows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla LL(1)\n",
    "\n",
    "Una vez tenemos todos los conjuntos `First` y `Follow` calculados, construiremos una tabla `T`, donde asociaremos a cada par no-terminal `X` / token `t` una producción (a lo sumo). Dicha producción es la única que tiene sentido aplicar si se debe expandir el no-terminal `X` y el token actual es `t`.\n",
    "\n",
    "Las reglas generales para generar esta tabla son las siguientes:\n",
    "\n",
    "1. Si `X` $\\to$ `W` y `t` $\\in V_t$ pertenece al `First(W)` entonces `T[X,t] = X` $\\to$ `W`.\n",
    "2. Si `X` $\\to$ `W` con $\\epsilon \\in$ `First(W)` y `t` pertenece al `Follow(X)` entonces `T[X,t] = X` $\\to$ `W`.\n",
    "\n",
    "Si al aplicar estas reglas, en cada posición `T[X,t]` obtenemos a lo sumo una producción, entonces decimos que una gramática es LL(1). En caso contrario, tenemos al menos un conflicto, pues hay más de una producción que tiene sentido utilizar en algún caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parsing_table(G, firsts, follows):\n",
    "    # init parsing table\n",
    "    M = {}\n",
    "    \n",
    "    # P: X -> alpha\n",
    "    for production in G.Productions:\n",
    "        X = production.Left\n",
    "        alpha = production.Right\n",
    "        \n",
    "    \n",
    "        ###################################################\n",
    "        # working with symbols on First(alpha) ...\n",
    "        ###################################################\n",
    "        \n",
    "        if(alpha.IsEpsilon):\n",
    "            for symbol in follows[X]:\n",
    "                if(symbol in M):\n",
    "                    raise Exception('Conflict')\n",
    "                M[X, symbol] = [production]\n",
    "        \n",
    "        else:\n",
    "            for symbol in firsts[alpha]:\n",
    "                if(symbol in M):\n",
    "                    raise Exception('Conflict')\n",
    "                M[X, symbol] = [production]\n",
    "        ###################################################\n",
    "        # working with epsilon...\n",
    "        ###################################################\n",
    "        #                   <CODE_HERE>                   #\n",
    "        ###################################################\n",
    "    \n",
    "    # parsing table is ready!!!\n",
    "    return M            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos que el algoritmo está bien implementado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = build_parsing_table(G, firsts, follows)\n",
    "\n",
    "assert M == hulk.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Descendente No Recursivo\n",
    "\n",
    "Una vez obtenida la tabla LL(1) podemos escribir un algoritmo de parsing descendente no recursivo. La idea general consiste en emplear una pila de símbolos, donde iremos construyendo la forma oracional que eventualmente derivará en la cadena a reconocer. Si leemos la pila desde el tope hasta el fondo, en todo momento tendremos una forma oracional que debe generar la parte de la cadena no reconocida.\n",
    "\n",
    "El símbolo en el tope de la pila representa el terminal o no-terminal a analizar. En caso de ser un terminal, debe coincidir con el token analizado. En caso de ser un no-terminal, se consulta la tabla LL(1) y se ejecuta la producción correspondiente, insertando en la pila (en orden inverso) la forma oracional en que deriva el no-terminal extraído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import stack\n",
    "\n",
    "\n",
    "def metodo_predictivo_no_recursivo(G, M=None, firsts=None, follows=None):\n",
    "    \n",
    "    # checking table...\n",
    "    if M is None:\n",
    "        if firsts is None:\n",
    "            firsts = compute_firsts(G)\n",
    "        if follows is None:\n",
    "            follows = compute_follows(G, firsts)\n",
    "        M = build_parsing_table(G, firsts, follows)\n",
    "    \n",
    "    \n",
    "    # parser construction...\n",
    "    def parser(w):\n",
    "        \n",
    "        stack = [G.startSymbol]\n",
    "        cursor = 0\n",
    "        output = []\n",
    "        ###################################################\n",
    "        # w ends with $ (G.EOF)\n",
    "        while True:\n",
    "            \n",
    "            if stack == []:\n",
    "                break\n",
    "            top = stack.pop()\n",
    "            a = w[cursor]\n",
    "            print(top)\n",
    "            if top.IsTerminal:\n",
    "                if top == a:\n",
    "                    cursor += 1\n",
    "                    if cursor == len(w):\n",
    "                        break\n",
    "                else:\n",
    "                    raise Exception('Syntax error')\n",
    "            else:\n",
    "                try:\n",
    "                    P = M[top, a][0]\n",
    "                except KeyError:\n",
    "                    raise Exception('Syntax error')\n",
    "                output.append(P)\n",
    "                for symbol in reversed(P.Right):\n",
    "                    stack.append(symbol)\n",
    "\n",
    "            \n",
    "        # left parse is ready!!!\n",
    "        return output\n",
    "    \n",
    "    # parser is ready!!!\n",
    "    return parser\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos que el algoritmo está bien implementado. El parse izquierdo para la cadena `\"n * n * n + n * n + n + n $\"` es:\n",
    "```\n",
    "E -> T X\n",
    "T -> F Y\n",
    "F -> num\n",
    "Y -> * F Y\n",
    "F -> num\n",
    "Y -> * F Y\n",
    "F -> num\n",
    "Y -> e\n",
    "X -> + T X\n",
    "T -> F Y\n",
    "F -> num\n",
    "Y -> * F Y\n",
    "F -> num\n",
    "Y -> e\n",
    "X -> + T X\n",
    "T -> F Y\n",
    "F -> num\n",
    "Y -> e\n",
    "X -> + T X\n",
    "T -> F Y\n",
    "F -> num\n",
    "Y -> e\n",
    "X -> e\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "T\n",
      "F\n",
      "num\n",
      "Y\n",
      "*\n",
      "F\n",
      "num\n",
      "Y\n",
      "*\n",
      "F\n",
      "num\n",
      "Y\n",
      "X\n",
      "+\n",
      "T\n",
      "F\n",
      "num\n",
      "Y\n",
      "*\n",
      "F\n",
      "num\n",
      "Y\n",
      "X\n",
      "+\n",
      "T\n",
      "F\n",
      "num\n",
      "Y\n",
      "X\n",
      "+\n",
      "T\n",
      "F\n",
      "num\n",
      "Y\n",
      "X\n"
     ]
    }
   ],
   "source": [
    "parser = metodo_predictivo_no_recursivo(G, M)\n",
    "left_parse = parser([num, star, num, star, num, plus, num, star, num, plus, num, plus, num, G.EOF])\n",
    "\n",
    "assert left_parse == [ \n",
    "   Production(E, Sentence(T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, Sentence(star, F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, Sentence(star, F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, Sentence(plus, T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, Sentence(star, F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, Sentence(plus, T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, Sentence(plus, T, X)),\n",
    "   Production(T, Sentence(F, Y)),\n",
    "   Production(F, Sentence(num)),\n",
    "   Production(Y, G.Epsilon),\n",
    "   Production(X, G.Epsilon),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos\n",
    "\n",
    "Probemos el generador de parser implementado con otras gramáticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+\n",
      "├── *\n",
      "│   ├── num\n",
      "│   └── *\n",
      "│       ├── num\n",
      "│       └── num\n",
      "└── +\n",
      "    ├── *\n",
      "    │   ├── num\n",
      "    │   └── num\n",
      "    └── +\n",
      "        ├── num\n",
      "        └── num\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from typing_extensions import Self\n",
    "# from asyncio.windows_events import NULL\n",
    "from audioop import reverse\n",
    "from textwrap import indent\n",
    "from time import thread_time_ns\n",
    "from turtle import right\n",
    "from typing import List, Tuple\n",
    "from unittest import result\n",
    "from anytree import RenderTree\n",
    "from anytree import Node as RenderNode\n",
    "from matplotlib import test\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, value, leftchildren , rightchildren) -> None:\n",
    "        self.leftchildren = leftchildren\n",
    "        self.rightchildren = rightchildren\n",
    "        self.value = value\n",
    "        \n",
    "    \n",
    "    def eval(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class NonTerminalNode(Node):\n",
    "    def __init__(self, value, leftchildren, rightchildren) -> None:\n",
    "        super().__init__(value, leftchildren, rightchildren)\n",
    "\n",
    "\n",
    "class BinaryNode(Node):\n",
    "   pass\n",
    "\n",
    "class BinaryOperationNode(BinaryNode):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "class PlusNode(BinaryNode):\n",
    "    def __init__(self, value, leftchildren, rightchildren) -> None:\n",
    "        super().__init__(value, leftchildren, rightchildren)\n",
    "    def eval(self):\n",
    "        return self.leftchildren.eval() + self.rightchildren.eval()\n",
    "    \n",
    "class MinusNode(BinaryNode):\n",
    "    def eval(self):\n",
    "        return self.leftchildren.eval() - self.rightchildren.eval()\n",
    "\n",
    "class DivNode(BinaryNode):\n",
    "    def eval(self):\n",
    "        return self.leftchildren.eval() / self.rightchildren.eval()\n",
    "    \n",
    "class StarNode(BinaryNode):\n",
    "    def __init__(self, value, leftchildren, rightchildren) -> None:\n",
    "        super().__init__(value, leftchildren, rightchildren)\n",
    "    def eval(self):\n",
    "        return self.leftchildren.eval() * self.rightchildren.eval()\n",
    "\n",
    "class NumNode(Node):\n",
    "    def __init__(self, value, leftchildren, rightchildren) -> None:\n",
    "        super().__init__(value, leftchildren = None , rightchildren = None)\n",
    "\n",
    "    def eval(self):\n",
    "        return float(self.value)\n",
    "\n",
    "class EpsilonNode(Node):\n",
    "    def __init__(self, value, leftchildren, rightchildren) -> None:\n",
    "        super().__init__(value, leftchildren = None, rightchildren = None)\n",
    "    \n",
    "\n",
    "        \n",
    "terminal_to_node = {\n",
    "    plus: PlusNode,\n",
    "    minus: MinusNode,\n",
    "    star: StarNode,\n",
    "    div: DivNode,\n",
    "    num: NumNode\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "def get_derivation_tree(left_parse: List[Production]) -> RenderNode:\n",
    "    root = RenderNode(left_parse[0].Left)\n",
    "    build_derivation_tree(root, left_parse)\n",
    "    return root\n",
    "\n",
    "\n",
    "\n",
    "def build_derivation_tree(node: RenderNode, left_parse: List[Production]) :\n",
    "    global count\n",
    "\n",
    "    if count == len(left_parse):\n",
    "        return\n",
    "\n",
    "    production = left_parse[count]\n",
    "    \n",
    "    new_node = None\n",
    "    if production.Right.IsEpsilon:\n",
    "        new_node = RenderNode('e', parent=node)\n",
    "        return\n",
    "\n",
    "    for symbol in (production.Right):\n",
    "        if symbol.IsTerminal:\n",
    "            new_node = RenderNode(symbol, parent=node)\n",
    "        else:\n",
    "            new_node = RenderNode(symbol, parent=node)\n",
    "            count+=1\n",
    "            build_derivation_tree(new_node, left_parse)\n",
    "\n",
    "    return\n",
    "\n",
    "count = 0\n",
    "def print_tree(tree):\n",
    "    for pre, fill, node in RenderTree(tree):\n",
    "        print(\"%s%s\" % (pre, node.name))\n",
    "\n",
    "\n",
    "def delete_epsilon(root:RenderNode):\n",
    "    if root.name == 'e':\n",
    "        root.parent = None\n",
    "        return\n",
    "    for child in root.children:\n",
    "        delete_epsilon(child)\n",
    "    \n",
    "    return root\n",
    "\n",
    "def delete_node_leaf(root : RenderNode):\n",
    "    if(len(root.children) == 0 and type(root.name) == NonTerminal):\n",
    "        root.parent = None\n",
    "        return\n",
    "    else:\n",
    "        for i in root.children:\n",
    "            delete_node_leaf(i)\n",
    "    # preorder_traversal(root)\n",
    "    return root\n",
    " \n",
    "def upadate_node_witch_only_children(root : RenderNode ) :\n",
    "    if (len(root.children) == 1 and root.children[0].name.Name == 'num' and type(root.name) == NonTerminal):\n",
    "        for i in root.children:\n",
    "            if(not root.parent == None):\n",
    "                i.parent = root.parent\n",
    "                # index = root.parent.children.index(root)\n",
    "                root.parent = None  \n",
    "            else:\n",
    "                i.parent = None\n",
    "                global firsts_node_in_tree\n",
    "                firsts_node_in_tree = i\n",
    "            # i.parent = None\n",
    "            # i.children = root.children.copy() \n",
    "        return\n",
    "    else:\n",
    "        for i in root.children:\n",
    "            upadate_node_witch_only_children(i)\n",
    "    \n",
    "    return root \n",
    "\n",
    "def move_operator(root : RenderNode):\n",
    "    global operator_change\n",
    "    if(len(root.children)== 0):\n",
    "        return\n",
    "    for i in root.children:\n",
    "        if(i.name.Name == '+' or i.name.Name == '-' or i.name.Name == '/' or i.name.Name == '*'):\n",
    "            \n",
    "            if(type(root.name) == NonTerminal):\n",
    "                    i_children = i.children\n",
    "                    for j in root.children:\n",
    "                        if not j == i:\n",
    "                            j.parent = i\n",
    "                    if root.parent == None:\n",
    "                        global first_node_in_tree\n",
    "                        first_node_in_tree = i\n",
    "                        new_node = RenderNode(root.name, parent=i)\n",
    "                        new_node.children = i_children\n",
    "                        root.parent = None\n",
    "                        # root.children = i_children\n",
    "                            \n",
    "                    else:\n",
    "                        i.parent = root.parent\n",
    "                        root.parent = i\n",
    "                        root.children = i_children\n",
    "                     \n",
    "                   \n",
    "                    operator_change = True\n",
    "            else :\n",
    "                move_operator(i)\n",
    "            \n",
    "        else : \n",
    "            delete_node_leaf(root)\n",
    "            move_operator(i)\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "def count_node(root : RenderNode):\n",
    "    count = 0\n",
    "    for i in root.children:\n",
    "        if(type(i) == NumNode):\n",
    "            count += 1\n",
    "        else:\n",
    "            count += count_node(i)\n",
    "    return count + 1\n",
    "\n",
    "def are_non_terminals_in_tree(root):\n",
    "    stack = [root]\n",
    "    while len(stack) > 0:\n",
    "        node = stack.pop()\n",
    "        if type(node.name) == NonTerminal:\n",
    "            return True\n",
    "        for child in node.children:\n",
    "            stack.append(child)\n",
    "\n",
    "    return False\n",
    "\n",
    "node_with_one_child_change = False\n",
    "operator_change = False\n",
    "\n",
    "first_node_in_tree = None\n",
    "\n",
    "def build_ast(root: RenderNode):\n",
    "    # print_tree(root)\n",
    "    global first_node_in_tree\n",
    "    global node_with_one_child_change\n",
    "    first_node_in_tree = root\n",
    "    node_with_one_child_change = False\n",
    "    delete_epsilon(first_node_in_tree)\n",
    "    delete_node_leaf(first_node_in_tree)\n",
    "    while(True):\n",
    "        x = count_node(first_node_in_tree)\n",
    "        upadate_node_witch_only_children(first_node_in_tree)\n",
    "        y = count_node(first_node_in_tree)\n",
    "        if(x == y):\n",
    "            break\n",
    "\n",
    "    \n",
    "    global operator_change\n",
    "    are_non_terminals = True\n",
    "    \n",
    "    while(are_non_terminals):\n",
    "\n",
    "        move_operator(first_node_in_tree)\n",
    "        while(True):\n",
    "            x = count_node(first_node_in_tree)\n",
    "            upadate_node_witch_only_children(first_node_in_tree)\n",
    "            y = count_node(first_node_in_tree)\n",
    "            \n",
    "            if(x == y):\n",
    "                break\n",
    "        \n",
    "        operator_change = False\n",
    "        are_non_terminals = are_non_terminals_in_tree(first_node_in_tree)\n",
    "        \n",
    "    return first_node_in_tree\n",
    "\n",
    "x = get_derivation_tree(left_parse)\n",
    "y = build_ast(x)\n",
    "print_tree(y)\n",
    "\n",
    "tree = [y]\n",
    "index = 0\n",
    "def representation_of_binarytree_in_array(root,count):\n",
    "    if(root == None) : return\n",
    "    global tree\n",
    "    if(len(root.children) == 0):\n",
    "        tree.append(None)\n",
    "        tree.append(None)\n",
    "        \n",
    "        return\n",
    "    for child in root.children :\n",
    "      tree.append(child)\n",
    "    global index\n",
    "    while(index < len(tree) - 1):\n",
    "        index+= 1\n",
    "        representation_of_binarytree_in_array(tree[index],count)\n",
    "representation_of_binarytree_in_array(y,count_node(y))\n",
    "\n",
    "values_to_process = []\n",
    "\n",
    "def build_ast_n(list, i, n):\n",
    "    if(i >= n):\n",
    "        return\n",
    "    if (list[i] == None):\n",
    "        return \n",
    "    root  = terminal_to_node[list[i].name](list[i].name,None, None)\n",
    "    if(i < n):\n",
    "        if(list[i].name == 'num'):\n",
    "            \n",
    "            return\n",
    "        else:\n",
    "            \n",
    "            root.leftchildren = build_ast_n(list, 2 * i + 1, n)\n",
    "            root.rightchildren = build_ast_n(list, 2 * i + 2, n)\n",
    "    return root\n",
    "\n",
    "def assing_values(root):\n",
    "    global values_to_process\n",
    "    if root == None:\n",
    "        return\n",
    "    if type(root) == NumNode :\n",
    "        root.value = values_to_process.pop(0)\n",
    "        # print(values_to_process)\n",
    "        return\n",
    "    assing_values(root.leftchildren)\n",
    "    assing_values(root.rightchildren)\n",
    "    \n",
    "    \n",
    "def print_ast(tree):\n",
    "    print(tree.value)\n",
    "    for x in tree.children:\n",
    "        print_ast(x)\n",
    "\n",
    "def print_inOrder(root):\n",
    "    if(root != None):\n",
    "        print(root.value )\n",
    "        print_inOrder(root.leftchildren)\n",
    "        print_inOrder(root.rightchildren)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.0\n"
     ]
    }
   ],
   "source": [
    "class TokenNonTerminal :\n",
    "    def __init__(self,token):\n",
    "        self.token = token\n",
    "class TokenTerminal :\n",
    "    def __init__(self, token,lexema):\n",
    "        self.token = token\n",
    "        self.lexema = lexema\n",
    "\n",
    "def tokenizar(S):\n",
    "    global values_to_process\n",
    "    values_to_process = []\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    while i < len(S):\n",
    "        if S[i].isnumeric():\n",
    "            next_token = False\n",
    "            current_number = S[i]\n",
    "            if (not i == len(S)-1):\n",
    "                while not next_token:    \n",
    "                    if S[i+1].isnumeric():\n",
    "                        current_number = S[i] +  S[i+1]\n",
    "                        i += 1\n",
    "                        if(i == len(S)- 1):\n",
    "                            break\n",
    "                    else : \n",
    "                        next_token = True\n",
    "            tokens.append(TokenTerminal('num', float(current_number)))\n",
    "            \n",
    "            values_to_process.append(float(current_number))\n",
    "        elif (S[i] == '('):\n",
    "            tokens.append(TokenTerminal('opar','('))\n",
    "        elif (S[i] == ')') :\n",
    "            tokens.append(TokenTerminal('cpar','('))\n",
    "        elif (S[i] == '+') :\n",
    "            tokens.append(TokenTerminal('plus','+'))\n",
    "        elif (S[i] == '-') :\n",
    "            tokens.append(TokenTerminal('minus','-'))\n",
    "        elif (S[i] == '*') :\n",
    "            tokens.append(TokenTerminal('star','*'))\n",
    "        elif (S[i] == '/') :\n",
    "            tokens.append(TokenTerminal('div','/'))\n",
    "        i+=1\n",
    "    return tokens\n",
    "\n",
    "\n",
    "tokens = tokenizar('3*4*2+1*8+3+6')\n",
    "\n",
    "z = build_ast_n(tree , 0 , len(tree))\n",
    "\n",
    "assing_values(z)\n",
    "print(z.eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gramática 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Terminals:\n",
      "\tS, A, B\n",
      "Terminals:\n",
      "\ta, b\n",
      "Productions:\n",
      "\t[S -> A B, A -> a A, A -> a, B -> b B, B -> b]\n"
     ]
    }
   ],
   "source": [
    "G = Grammar()\n",
    "S = G.NonTerminal('S', True)\n",
    "A,B = G.NonTerminals('A B')\n",
    "a,b = G.Terminals('a b')\n",
    "\n",
    "S %= A + B\n",
    "A %= a + A | a\n",
    "B %= b + B | b\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  --->  {'a'}-False\n",
      "b  --->  {'b'}-False\n",
      "S  --->  {'a'}-False\n",
      "A  --->  {'a'}-False\n",
      "B  --->  {'b'}-False\n",
      "A B  --->  {'a'}-False\n",
      "a A  --->  {'a'}-False\n",
      "a  --->  {'a'}-False\n",
      "b B  --->  {'b'}-False\n",
      "b  --->  {'b'}-False\n"
     ]
    }
   ],
   "source": [
    "firsts = compute_firsts(G)\n",
    "pprint(firsts)\n",
    "\n",
    "# print(inspect(firsts))\n",
    "assert firsts == {\n",
    "   a: ContainerSet(a , contains_epsilon=False),\n",
    "   b: ContainerSet(b , contains_epsilon=False),\n",
    "   S: ContainerSet(a , contains_epsilon=False),\n",
    "   A: ContainerSet(a , contains_epsilon=False),\n",
    "   B: ContainerSet(b , contains_epsilon=False),\n",
    "   Sentence(A, B): ContainerSet(a , contains_epsilon=False),\n",
    "   Sentence(a, A): ContainerSet(a , contains_epsilon=False),\n",
    "   Sentence(a): ContainerSet(a , contains_epsilon=False),\n",
    "   Sentence(b, B): ContainerSet(b , contains_epsilon=False),\n",
    "   Sentence(b): ContainerSet(b , contains_epsilon=False) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S  --->  {'$'}-False\n",
      "A  --->  {'b'}-False\n",
      "B  --->  {'$'}-False\n"
     ]
    }
   ],
   "source": [
    "follows = compute_follows(G, firsts)\n",
    "pprint(follows)\n",
    "\n",
    "# print(inspect(follows))\n",
    "assert follows == {\n",
    "   S: ContainerSet(G.EOF , contains_epsilon=False),\n",
    "   A: ContainerSet(b , contains_epsilon=False),\n",
    "   B: ContainerSet(G.EOF , contains_epsilon=False) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('S', 'a'): [S -> A B], ('A', 'a'): [A -> a], ('B', 'b'): [B -> b]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = build_parsing_table(G, firsts, follows)\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gramatica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Terminals:\n",
      "\tS, A, B, C\n",
      "Terminals:\n",
      "\ta, b, c, d, f\n",
      "Productions:\n",
      "\t[S -> a A, S -> B C, S -> f B f, A -> a A, A -> e, B -> b B, B -> e, C -> c C, C -> d]\n"
     ]
    }
   ],
   "source": [
    "G = Grammar()\n",
    "S = G.NonTerminal('S', True)\n",
    "A,B,C = G.NonTerminals('A B C')\n",
    "a,b,c,d,f = G.Terminals('a b c d f')\n",
    "\n",
    "S %= a + A | B + C | f + B + f\n",
    "A %= a + A | G.Epsilon\n",
    "B %= b + B | G.Epsilon\n",
    "C %= c + C | d\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  --->  {'a'}-False\n",
      "b  --->  {'b'}-False\n",
      "c  --->  {'c'}-False\n",
      "d  --->  {'d'}-False\n",
      "f  --->  {'f'}-False\n",
      "S  --->  {'b', 'a', 'c', 'd', 'f'}-False\n",
      "A  --->  {'a'}-True\n",
      "B  --->  {'b'}-True\n",
      "C  --->  {'d', 'c'}-False\n",
      "a A  --->  {'a'}-False\n",
      "B C  --->  {'b', 'c', 'd'}-False\n",
      "f B f  --->  {'f'}-False\n",
      "e  --->  set()-True\n",
      "b B  --->  {'b'}-False\n",
      "c C  --->  {'c'}-False\n",
      "d  --->  {'d'}-False\n",
      "{'a'}-False\n"
     ]
    }
   ],
   "source": [
    "firsts = compute_firsts(G)\n",
    "pprint(firsts)\n",
    "pprint(firsts[Sentence(a, A)])\n",
    "# print(inspect(firsts))\n",
    "assert firsts == {\n",
    "   a: ContainerSet(a , contains_epsilon=False),\n",
    "   b: ContainerSet(b , contains_epsilon=False),\n",
    "   c: ContainerSet(c , contains_epsilon=False),\n",
    "   d: ContainerSet(d , contains_epsilon=False),\n",
    "   f: ContainerSet(f , contains_epsilon=False),\n",
    "   S: ContainerSet(d, a, f, c, b , contains_epsilon=False),\n",
    "   A: ContainerSet(a , contains_epsilon=True),\n",
    "   B: ContainerSet(b , contains_epsilon=True),\n",
    "   C: ContainerSet(c, d , contains_epsilon=False),\n",
    "   Sentence(a, A): ContainerSet(a , contains_epsilon=False),\n",
    "   Sentence(B, C): ContainerSet(d, c, b , contains_epsilon=False),\n",
    "   Sentence(f, B, f): ContainerSet(f , contains_epsilon=False),\n",
    "   G.Epsilon: ContainerSet( contains_epsilon=True),\n",
    "   Sentence(b, B): ContainerSet(b , contains_epsilon=False),\n",
    "   Sentence(c, C): ContainerSet(c , contains_epsilon=False),\n",
    "   Sentence(d): ContainerSet(d , contains_epsilon=False) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S  --->  {'$'}-False\n",
      "A  --->  {'$'}-False\n",
      "B  --->  {'c', 'd', 'f'}-False\n",
      "C  --->  {'$'}-False\n"
     ]
    }
   ],
   "source": [
    "follows = compute_follows(G, firsts)\n",
    "pprint(follows)\n",
    "\n",
    "# print(inspect(follows))\n",
    "assert follows == {\n",
    "   S: ContainerSet(G.EOF , contains_epsilon=False),\n",
    "   A: ContainerSet(G.EOF , contains_epsilon=False),\n",
    "   B: ContainerSet(d, f, c , contains_epsilon=False),\n",
    "   C: ContainerSet(G.EOF , contains_epsilon=False) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('S', 'a')  --->  [S -> a A]\n",
      "('S', 'b')  --->  [S -> B C]\n",
      "('S', 'c')  --->  [S -> B C]\n",
      "('S', 'd')  --->  [S -> B C]\n",
      "('S', 'f')  --->  [S -> f B f]\n",
      "('A', 'a')  --->  [A -> a A]\n",
      "('A', '$')  --->  [A -> e]\n",
      "('B', 'b')  --->  [B -> b B]\n",
      "('B', 'c')  --->  [B -> e]\n",
      "('B', 'd')  --->  [B -> e]\n",
      "('B', 'f')  --->  [B -> e]\n",
      "('C', 'c')  --->  [C -> c C]\n",
      "('C', 'd')  --->  [C -> d]\n"
     ]
    }
   ],
   "source": [
    "M = build_parsing_table(G, firsts, follows)\n",
    "pprint(M)\n",
    "\n",
    "# print(inspect(M))\n",
    "assert M == {\n",
    "   ( S, a, ): [ Production(S, Sentence(a, A)), ],\n",
    "   ( S, c, ): [ Production(S, Sentence(B, C)), ],\n",
    "   ( S, b, ): [ Production(S, Sentence(B, C)), ],\n",
    "   ( S, d, ): [ Production(S, Sentence(B, C)), ],\n",
    "   ( S, f, ): [ Production(S, Sentence(f, B, f)), ],\n",
    "   ( A, a, ): [ Production(A, Sentence(a, A)), ],\n",
    "   ( A, G.EOF, ): [ Production(A, G.Epsilon), ],\n",
    "   ( B, b, ): [ Production(B, Sentence(b, B)), ],\n",
    "   ( B, c, ): [ Production(B, G.Epsilon), ],\n",
    "   ( B, f, ): [ Production(B, G.Epsilon), ],\n",
    "   ( B, d, ): [ Production(B, G.Epsilon), ],\n",
    "   ( C, c, ): [ Production(C, Sentence(c, C)), ],\n",
    "   ( C, d, ): [ Production(C, Sentence(d)), ] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "B\n",
      "b\n",
      "B\n",
      "b\n",
      "B\n",
      "C\n",
      "d\n",
      "[\n",
      "   S -> B C\n",
      "   B -> b B\n",
      "   B -> b B\n",
      "   B -> e\n",
      "   C -> d\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "parser = metodo_predictivo_no_recursivo(G, M)\n",
    "\n",
    "left_parse = parser([b, b, d, G.EOF])\n",
    "pprint(left_parse)\n",
    "\n",
    "# print(inspect(left_parse))\n",
    "assert left_parse == [ \n",
    "   Production(S, Sentence(B, C)),\n",
    "   Production(B, Sentence(b, B)),\n",
    "   Production(B, Sentence(b, B)),\n",
    "   Production(B, G.Epsilon),\n",
    "   Production(C, Sentence(d)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstrucción del árbol de derivación y evaluación\n",
    "- Implemente un algoritmo básico de tokenización para a partir de un `string` obtener la sequencia de tokens correspondiente. Note que los símbolos terminales de la gramática coincide con los \"tipos\" de tokens, pero no contienen el lexemas.\n",
    "- Reconstruya el árbol de derivación a partir del parse izquierdo que devuelve el parser.\n",
    "- Utilice el árbol de derivación para evaluar la expresión. Note que la estructura de la gramática causa que los operadores (+, -, \\*, /) asocien hacia la derecha, lo cual conlleva problemas si se evalúa recursivamente sin considerar tal característica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
