{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Práctica #5 (Compilación)\n",
    "\n",
    "En esta clase estaremos adaptando el evaluador de expresiones aritméticas para trabajar sobre un _AST (Abstact Syntax Tree)_. Recordemos que el AST posee una estructura más cómoda para evaluar las reglas semánticas que el árbol de derivación. Además, evaluar en el AST en lugar que desde las reglas de la gramática atributada, simplifica significativamente la implementación de las reglas semánticas.\n",
    "\n",
    "## Jerarquía del AST\n",
    "\n",
    "Definamos una jerarquía de clases para los nodos del _AST_ del lenguaje de expresiones aritméticas. Utilizaremos las clases `Node` y `BinaryNode` como definiciones abstractas para agrupar y compactar la implementación de sus descendientes. Los nodos del AST serán exclusivamente instancias de `ConstantNumberNode`, `PlusNode`, `MinusNode`, `StarNode` y `DivNode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def evaluate(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class ConstantNumberNode(Node):\n",
    "    def __init__(self, lex):\n",
    "        self.lex = lex\n",
    "        self.value = float(lex)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        # Insert your code here!!!\n",
    "        return self.value\n",
    "        \n",
    "\n",
    "class BinaryNode(Node):\n",
    "    def __init__(self, left: Node, right: Node):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "    def evaluate(self):\n",
    "        ## Insert your code here!!!\n",
    "        # lvalue = ???\n",
    "        # rvalue = ???\n",
    "        lvalue = self.left.evaluate()\n",
    "        rvalue = self.right.evaluate()\n",
    "        return self.operate(lvalue, rvalue)\n",
    "    \n",
    "    @staticmethod\n",
    "    def operate(lvalue, rvalue):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "\n",
    "class PlusNode(BinaryNode):\n",
    "    @staticmethod\n",
    "    def operate(lvalue, rvalue):\n",
    "        # Insert your code here!!!\n",
    "        return lvalue + rvalue\n",
    "        \n",
    "\n",
    "class MinusNode(BinaryNode):\n",
    "    @staticmethod\n",
    "    def operate(lvalue, rvalue):\n",
    "        # Insert your code here!!!\n",
    "        return lvalue - rvalue\n",
    "\n",
    "class StarNode(BinaryNode):\n",
    "    @staticmethod\n",
    "    def operate(lvalue, rvalue):\n",
    "        # Insert your code here!!!\n",
    "        return lvalue * rvalue\n",
    "\n",
    "class DivNode(BinaryNode):\n",
    "    @staticmethod\n",
    "    def operate(lvalue, rvalue):\n",
    "        # Insert your code here!!!\n",
    "        return lvalue / rvalue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como luce una instancia concreta de un AST de expresiones. Nótese que la precedencia de los operadores debe seguir atrapada en el AST puesto que solo se desecharon los atributos sintácticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\__<expr> PlusNode <expr>\n",
      "\t\\__<expr> MinusNode <expr>\n",
      "\t\t\\__ ConstantNumberNode: 5\n",
      "\t\t\\__ ConstantNumberNode: 6\n",
      "\t\\__ ConstantNumberNode: 9\n"
     ]
    }
   ],
   "source": [
    "from cmp.ast import get_printer\n",
    "printer = get_printer(AtomicNode=ConstantNumberNode, BinaryNode=BinaryNode)\n",
    "\n",
    "print(printer(\n",
    "    PlusNode(\n",
    "        MinusNode(\n",
    "            ConstantNumberNode('5'),\n",
    "            ConstantNumberNode('6')\n",
    "        ), ConstantNumberNode('9')\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del AST\n",
    "\n",
    "Pasemos a definir la gramática del lenguaje de expresiones aritméticas junto con las reglas semánticas para formar el _AST_. Las reglas quedarán muy similares a las de la clase anterior, pero esta vez en lugar de operar los valores, construiremos el nodo del AST que denota la operación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Grammar\n",
    "from cmp.utils import pprint, inspect\n",
    "\n",
    "G = Grammar()\n",
    "E = G.NonTerminal('E', True)\n",
    "T, F, X, Y = G.NonTerminals('T F X Y')\n",
    "plus, minus, star, div, opar, cpar, num = G.Terminals('+ - * / ( ) num')\n",
    "\n",
    "############################ BEGIN PRODUCTIONS ############################\n",
    "# ======================================================================= #\n",
    "#                                                                         #\n",
    "# ========================== { E --> T X } ============================== #\n",
    "#                                                                         #\n",
    "E %= T + X, lambda h,s: s[2], None, lambda h,s: s[1]                    #\n",
    "#                                                                         #\n",
    "# =================== { X --> + T X | - T X | epsilon } ================= #\n",
    "#                                                                         #\n",
    "X %= plus + T + X, lambda h,s: s[3], None, None, lambda h,s: PlusNode(s[2], h[0])                             \n",
    "X %= minus + T + X, lambda h,s: s[3], None, None, lambda h,s: MinusNode(h[0], s[2])                              \n",
    "X %= G.Epsilon, lambda h,s: h[0]                                                    \n",
    "#                                                                         #\n",
    "# ============================ { T --> F Y } ============================ #\n",
    "#                                                                         #\n",
    "T %= F + Y, lambda h,s: s[2], None, lambda h,s: s[1]                                            \n",
    "#                                                                         #\n",
    "# ==================== { Y --> * F Y | / F Y | epsilon } ================ #\n",
    "#                                                                         #\n",
    "Y %= star + F + Y, lambda h,s: s[3], None, None, lambda h,s: StarNode(h[0], s[2])                             \n",
    "Y %= div + F + Y, lambda h,s: s[3], None, None, lambda h,s: DivNode(h[0], s[2])                              \n",
    "Y %= G.Epsilon, lambda h,s: h[0]                                                    \n",
    "#                                                                         #\n",
    "# ======================= { F --> num | ( E ) } ========================= #\n",
    "F %= num, lambda h,s: ConstantNumberNode(s[1]), None                                                    \n",
    "F %= opar + E + cpar, lambda h,s: s[2], None, None, None                           \n",
    "#                                                                         #\n",
    "# ======================================================================= #\n",
    "############################# END PRODUCTIONS #############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensamblemos el pipeline de evaluación con los elementos que hemos ido implementando a lo largo de las pasadas clases.\n",
    "\n",
    "Se realizará la siguiente cadena de transformaciones:\n",
    "```\n",
    "Entrada -> Tokens -> Parse Izquierdo -> AST -> Resultado\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.utils import Token\n",
    "from cmp.languages import BasicHulk\n",
    "from cmp.tools.parsing import build_parsing_table, metodo_predictivo_no_recursivo\n",
    "from cmp.tools.evaluation import evaluate_parse\n",
    "\n",
    "hulk = BasicHulk(G)\n",
    "firsts = hulk.firsts\n",
    "follows = hulk.follows\n",
    "tokenize_text = hulk.tokenizer\n",
    "\n",
    "M = build_parsing_table(G, firsts, follows)\n",
    "parser = metodo_predictivo_no_recursivo(G, M, firsts, follows)\n",
    "\n",
    "\n",
    "def run_pipeline(text, tokenizer, value, parser, formatter):\n",
    "    tokens = tokenizer(text)\n",
    "    pprint(tokens, '================Tokens================')\n",
    "    left_parse = parser(tokens)\n",
    "    pprint(left_parse, '==============Left-Parse==============')\n",
    "    ast = evaluate_parse(left_parse, tokens)\n",
    "    pprint(formatter(ast), '=================AST==================')\n",
    "    result = ast.evaluate()\n",
    "\n",
    "    pprint(f'{text} = {result}', '================Result================')\n",
    "    assert result == value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos que la asociatividad de los operadores no se perdió."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Tokens================\n",
      "[\n",
      "   num: 1\n",
      "   -: -\n",
      "   num: 1\n",
      "   -: -\n",
      "   num: 1\n",
      "   $: $\n",
      "]\n",
      "==============Left-Parse==============\n",
      "[\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> num\n",
      "   Y -> e\n",
      "   X -> - T X\n",
      "   T -> F Y\n",
      "   F -> num\n",
      "   Y -> e\n",
      "   X -> - T X\n",
      "   T -> F Y\n",
      "   F -> num\n",
      "   Y -> e\n",
      "   X -> e\n",
      "]\n",
      "=================AST==================\n",
      "\\__<expr> MinusNode <expr>\n",
      "\t\\__<expr> MinusNode <expr>\n",
      "\t\t\\__ ConstantNumberNode: 1\n",
      "\t\t\\__ ConstantNumberNode: 1\n",
      "\t\\__ ConstantNumberNode: 1\n",
      "================Result================\n",
      "1 - 1 - 1 = -1.0\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('1 - 1 - 1', tokenize_text, -1,  parser, printer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Tokens================\n",
      "[\n",
      "   num: 1\n",
      "   -: -\n",
      "   (: (\n",
      "   num: 1\n",
      "   -: -\n",
      "   num: 1\n",
      "   ): )\n",
      "   $: $\n",
      "]\n",
      "==============Left-Parse==============\n",
      "[\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> num\n",
      "   Y -> e\n",
      "   X -> - T X\n",
      "   T -> F Y\n",
      "   F -> ( E )\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> num\n",
      "   Y -> e\n",
      "   X -> - T X\n",
      "   T -> F Y\n",
      "   F -> num\n",
      "   Y -> e\n",
      "   X -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "]\n",
      "=================AST==================\n",
      "\\__<expr> MinusNode <expr>\n",
      "\t\\__ ConstantNumberNode: 1\n",
      "\t\\__<expr> MinusNode <expr>\n",
      "\t\t\\__ ConstantNumberNode: 1\n",
      "\t\t\\__ ConstantNumberNode: 1\n",
      "================Result================\n",
      "1 - ( 1 - 1 ) = 1.0\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('1 - ( 1 - 1 )', tokenize_text, 1,  parser, printer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionando operador _potencia_\n",
    "\n",
    "Añadamos el operador potencia al lenguaje. Para ello, realizaremos las modificaciones pertinentes a cada una de las fases del evaluador. No será necesario **copia y pegar** código de otras clases, ni modificar el código fuente del módulo `cmp` que se distribuye junto al _notebook_.\n",
    "\n",
    "Usaremos el símbolo `^` para denotar al operador potencia. Este es un operador binario que computa $a^b$ siendo, `a` y `b` los operandos izquierdo y derecho respectivamente. Por ejemplo, `2 ^ 4` computa $2^4$. El operador potencia asocia hacia la derecha (contrario a los operadores: +, -, \\* y /). Por tanto, `4 ^ 3 ^ 2` computa $4^{3^2} = 4^9$ en lugar de $(4^3)^2 = 4^6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowNode(BinaryNode):\n",
    "    @staticmethod\n",
    "    def operate(lvalue, rvalue):\n",
    "        # Insert your code here!!!\n",
    "        return lvalue ** rvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Grammar()\n",
    "E = G.NonTerminal('E', True)\n",
    "T, F, X, Y, A, Z = G.NonTerminals('T F X Y A Z')\n",
    "plus, minus, star, div, opar, cpar, num, pow = G.Terminals('+ - * / ( ) num ^')\n",
    "\n",
    "############################ BEGIN PRODUCTIONS ############################\n",
    "# ======================================================================= #\n",
    "#                                                                         #\n",
    "# ========================== { E --> T X } ============================== #\n",
    "#                                                                         #\n",
    "E %= T + X, lambda h,s: s[2], None, lambda h,s: s[1]                    #\n",
    "#                                                                         #\n",
    "# =================== { X --> + T X | - T X | epsilon } ================= #\n",
    "#                                                                         #\n",
    "X %= plus + T + X, lambda h,s: s[3], None, None, lambda h,s: PlusNode(s[2], h[0])                             \n",
    "X %= minus + T + X, lambda h,s: s[3], None, None, lambda h,s: MinusNode(h[0], s[2])                              \n",
    "X %= G.Epsilon, lambda h,s: h[0]                                                    \n",
    "#                                                                         #\n",
    "# ============================ { T --> F Y } ============================ #\n",
    "#                                                                         #\n",
    "T %= F + Y, lambda h,s: s[2], None, lambda h,s: s[1]                                            \n",
    "#                                                                         #\n",
    "# ==================== { Y --> * F Y | / F Y | epsilon } ================ #\n",
    "#                                                                         #\n",
    "Y %= star + F + Y, lambda h,s: s[3], None, None, lambda h,s: StarNode(h[0], s[2])                             \n",
    "Y %= div + F + Y, lambda h,s: s[3], None, None, lambda h,s: DivNode(h[0], s[2])                           \n",
    "Y %= G.Epsilon, lambda h,s: h[0]                                                    \n",
    "#                                                                         #\n",
    "# ======================= { F --> num | ( E ) } ========================= #\n",
    "F %= A + Z, lambda h,s: s[2], None,  lambda h,s: s[1]\n",
    "A %= num, lambda h,s: ConstantNumberNode(s[1]), None                                                    \n",
    "A %= opar + E + cpar, lambda h,s: s[2], None, None, None      \n",
    "Z %= pow + F, lambda h,s: PowNode(h[0], s[2]), None, None\n",
    "Z %= G.Epsilon, lambda h,s: h[0]                  \n",
    "#                                                                         #\n",
    "# ======================================================================= #\n",
    "############################# END PRODUCTIONS #############################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.languages import UnknownToken\n",
    "\n",
    "\n",
    "fixed_tokens = { lex: Token(lex, G[lex]) for lex in '+ - * / ( ) ^'.split() }\n",
    "def tokenizer(G, fixed_tokens):\n",
    "        fixed_tokens = fixed_tokens\n",
    "\n",
    "        def tokenize_text(text: str):\n",
    "            tokens = []\n",
    "            splitted_text = text.split()\n",
    "            for i, item in enumerate(splitted_text):\n",
    "                try:\n",
    "                    float(item)\n",
    "                    token = Token(item, G['num'])\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        token = fixed_tokens[item]\n",
    "                    except KeyError:\n",
    "                        if i == len(splitted_text)-1:\n",
    "                            token = Token(item, G['id'])\n",
    "                        elif i < len(splitted_text) - 1 and splitted_text[i + 1] in ('+', '-', '*', '/', '(', ')', '^', '='):\n",
    "                            token = Token(item, G['id'])\n",
    "                        else:\n",
    "                            token = UnknownToken(item)\n",
    "                tokens.append(token)\n",
    "            eof = Token('$', G.EOF)\n",
    "            tokens.append(eof)\n",
    "            return tokens\n",
    "\n",
    "        return tokenize_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ayuda se proveen los conjunto _First_ y _Follow_ precomputados de lo que consideramos la gramática **natural** a obtener. De igual forma se tiene la tabla y parser LL(1). Siéntase libre de utilizar el código siguiente pero puede reemplazarlo por sus propias implementaciones en caso de que no pueda (o no entienda) cómo utilizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens <function tokenizer.<locals>.tokenize_text at 0x114e7e5f0>\n"
     ]
    }
   ],
   "source": [
    "from cmp.languages import PowHulk\n",
    "pow_hulk = PowHulk(G)\n",
    "\n",
    "firsts = pow_hulk.firsts\n",
    "follows = pow_hulk.follows\n",
    "\n",
    "tokenize_text = tokenizer(G, fixed_tokens)\n",
    "print('tokens', tokenize_text)\n",
    "\n",
    "from cmp.tools.parsing import build_parsing_table, metodo_predictivo_no_recursivo\n",
    "M = build_parsing_table(G, firsts, follows)\n",
    "parser = metodo_predictivo_no_recursivo(G, M, firsts, follows)\n",
    "v = (E, num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprobemos que el operador potencia asocia hacia la derecha.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Tokens================\n",
      "[\n",
      "   num: 4\n",
      "   ^: ^\n",
      "   num: 3\n",
      "   ^: ^\n",
      "   num: 2\n",
      "   $: $\n",
      "]\n",
      "==============Left-Parse==============\n",
      "[\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> ^ F\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> ^ F\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "]\n",
      "=================AST==================\n",
      "\\__<expr> PowNode <expr>\n",
      "\t\\__ ConstantNumberNode: 4\n",
      "\t\\__<expr> PowNode <expr>\n",
      "\t\t\\__ ConstantNumberNode: 3\n",
      "\t\t\\__ ConstantNumberNode: 2\n",
      "================Result================\n",
      "4 ^ 3 ^ 2 = 262144.0\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('4 ^ 3 ^ 2', tokenize_text, 262144, parser, printer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprobemos que tiene más precedencia que el resto de los operadores.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Tokens================\n",
      "[\n",
      "   num: 2\n",
      "   *: *\n",
      "   num: 3\n",
      "   ^: ^\n",
      "   num: 4\n",
      "   +: +\n",
      "   num: 1\n",
      "   *: *\n",
      "   num: 5\n",
      "   $: $\n",
      "]\n",
      "==============Left-Parse==============\n",
      "[\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> * F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> ^ F\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> + T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> * F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "]\n",
      "=================AST==================\n",
      "\\__<expr> PlusNode <expr>\n",
      "\t\\__<expr> StarNode <expr>\n",
      "\t\t\\__ ConstantNumberNode: 1\n",
      "\t\t\\__ ConstantNumberNode: 5\n",
      "\t\\__<expr> StarNode <expr>\n",
      "\t\t\\__ ConstantNumberNode: 2\n",
      "\t\t\\__<expr> PowNode <expr>\n",
      "\t\t\t\\__ ConstantNumberNode: 3\n",
      "\t\t\t\\__ ConstantNumberNode: 4\n",
      "================Result================\n",
      "2 * 3 ^ 4 + 1 * 5 = 167.0\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('2 * 3 ^ 4 + 1 * 5', tokenize_text, 167, parser, printer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprobemos que puede subordinarse a otros operadores usando paréntesis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Tokens================\n",
      "[\n",
      "   num: 3\n",
      "   ^: ^\n",
      "   (: (\n",
      "   num: 1\n",
      "   +: +\n",
      "   num: 1\n",
      "   ): )\n",
      "   ^: ^\n",
      "   num: 2\n",
      "   $: $\n",
      "]\n",
      "==============Left-Parse==============\n",
      "[\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> ^ F\n",
      "   F -> A Z\n",
      "   A -> ( E )\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> + T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "   Z -> ^ F\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "]\n",
      "=================AST==================\n",
      "\\__<expr> PowNode <expr>\n",
      "\t\\__ ConstantNumberNode: 3\n",
      "\t\\__<expr> PowNode <expr>\n",
      "\t\t\\__<expr> PlusNode <expr>\n",
      "\t\t\t\\__ ConstantNumberNode: 1\n",
      "\t\t\t\\__ ConstantNumberNode: 1\n",
      "\t\t\\__ ConstantNumberNode: 2\n",
      "================Result================\n",
      "3 ^ ( 1 + 1 ) ^ 2 = 81.0\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('3 ^ ( 1 + 1 ) ^ 2', tokenize_text, 81, parser, printer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionando _declaraciones de variables_\n",
    "\n",
    "Añadamos variables al lenguaje de expresiones para acercarnos más a `HULK`. Para ello, agregue la expresión `let-in` al lenguaje. Dicha expresión sigue la siguiente sintaxis:\n",
    "\n",
    "```\n",
    "let\n",
    "    <declaration-list>\n",
    "in\n",
    "    <expr>\n",
    "```\n",
    "donde `<expr>` denota cualquier expresión del lenguaje (incluyendo el propio `let-in`) y `<declaration-list>` representa una secuencia de declaraciones de la forma `<id> = <expr>` separadas por \"`,`\".\n",
    "\n",
    "El valor de evaluación de la expresión `let-in` es el valor de evaluación de `<expr>`.  \n",
    "Las variables declaradas en `<declaration-list>` serán visibles a partir de su declaración pero únicamente dentro de la expresión `let-in` que las contiene (incluye `<expr>`). Si `<expr>` contiene a su vez una expresión `let-in`, la declaración de una variable con el mismo nombre que una en el `let-in` padre **ocultará** la del padre.  \n",
    "Por ejemplo, la expresión:\n",
    "```\n",
    "let\n",
    "    x = 1,\n",
    "    y = 2\n",
    "in\n",
    "    3 + (let x = 4, z = 5 in x + y + z) + x\n",
    "```\n",
    "equivalente a:\n",
    "```\n",
    "let x = 1, y = 2 in 3 + (let x = 4, z = 5 in x + y + z) + x\n",
    "```\n",
    "evalúa `15`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetHulk:\n",
    "    def __init__(self, G: Grammar, fixed_tokens) -> None:\n",
    "        self.G = G,\n",
    "        self.fixed_tokens = fixed_tokens\n",
    "\n",
    "class VariableNode():\n",
    "    def __init__(self,id,dic):\n",
    "        self.id = id \n",
    "        self.dic = dic\n",
    "    @staticmethod\n",
    "    def evaluate(dic , id):\n",
    "        return dic[id]\n",
    "class AssignNode():\n",
    "\n",
    "    def __init__(self,id, value , assingNode):\n",
    "        self.value = value\n",
    "        self.id = id\n",
    "        self.assingNode = assingNode\n",
    "        self.dic = {}\n",
    "        self.dic[id] = value\n",
    "        if assingNode:\n",
    "            print(type(assingNode))\n",
    "            print(assingNode.dic)\n",
    "            for i,j in assingNode.dic:\n",
    "                print(i, 'valor')\n",
    "                print(j, 'valoooooor')\n",
    "                self.dic[i] = j\n",
    "\n",
    "    def evaluate(self):\n",
    "        return self.dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Grammar()\n",
    "E = G.NonTerminal('E', True)\n",
    "T, F, X, Y, A, Z , V , L ,I = G.NonTerminals('T  F X Y A Z V L I')\n",
    "plus, minus, star, div, opar, cpar, num, pow , equal, let, inh, id, comma = G.Terminals('+ - * / ( ) num ^ = let in id ,')\n",
    "\n",
    "############################ BEGIN PRODUCTIONS ############################\n",
    "# ======================================================================= #\n",
    "#                                                                         #\n",
    "# ========================== { E --> T X } ============================== #\n",
    "#                                                                         #\n",
    "E %= T + X, lambda h,s: s[2], None, lambda h,s: s[1]                    #\n",
    "#                                                                         #\n",
    "# =================== { X --> + T X | - T X | epsilon } ================= #\n",
    "#                                                                         #\n",
    "X %= plus + T + X, lambda h,s: s[3], None, None, lambda h,s: PlusNode(s[2], h[0])                             \n",
    "X %= minus + T + X, lambda h,s: s[3], None, None, lambda h,s: MinusNode(h[0], s[2])                              \n",
    "X %= G.Epsilon, lambda h,s: h[0]                                                    \n",
    "#                                                                         #\n",
    "# ============================ { T --> F Y } ============================ #\n",
    "#                                                                         #\n",
    "T %= F + Y, lambda h,s: s[2], None, lambda h,s: s[1]                                            \n",
    "#                                                                         #\n",
    "# ==================== { Y --> * F Y | / F Y | epsilon } ================ #\n",
    "#                                                                         #\n",
    "Y %= star + F + Y, lambda h,s: s[3], None, None, lambda h,s: StarNode(h[0], s[2])                             \n",
    "Y %= div + F + Y, lambda h,s: s[3], None, None, lambda h,s: DivNode(h[0], s[2])                           \n",
    "Y %= G.Epsilon, lambda h,s: h[0]                                                    \n",
    "#                                                                         #\n",
    "# ======================= { F --> AZ } ===================================#\n",
    "#\n",
    "F %= A + Z, lambda h,s: s[2], None,  lambda h,s: s[1]\n",
    "#\n",
    "#\n",
    "#======================{A --> num | (E) | let VI | id}=================================#\n",
    "#\n",
    "#\n",
    "A %= num, lambda h,s: ConstantNumberNode(s[1]), None                                                    \n",
    "A %= opar + E + cpar, lambda h,s: s[2], None, None, None  \n",
    "A %= let + V + I , lambda h,s: s[3], None, None, lambda h,s: s[2]\n",
    "A %= id, lambda h,s: VariableNode(h[0], s[1] ), None\n",
    "# \n",
    "# ===================={Z --> ^F | epsilon}================================#    \n",
    "Z %= pow + F, lambda h,s: PowNode(h[0], s[2]), None, None\n",
    "Z %= G.Epsilon, lambda h,s: h[0]                 \n",
    "#                                                                         \n",
    "#==========================={V --> id= EL}================================#\n",
    "#\n",
    "#\n",
    "V %= id + equal + E + L , lambda h,s : AssignNode(s[1],s[3], s[4]), None, None,None, None\n",
    "#\n",
    "#\n",
    "#==========================={L --> ,V | epsilon}================================#\n",
    "L %= comma + V , lambda h,s : s[2], None, None\n",
    "L %= G.Epsilon, lambda h,s : h[0]\n",
    "#\n",
    "#\n",
    "#==========================={I --> inh E}================================#\n",
    "#\n",
    "I %= inh + E , lambda h,s : s[2], None, None\n",
    "#\n",
    "############################# END PRODUCTIONS #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from cmp.pycompiler import Sentence\n",
    "from cmp.utils import ContainerSet\n",
    "\n",
    "\n",
    "def compute_local_first(firsts, alpha: Sentence):\n",
    "    first_alpha = ContainerSet()\n",
    "    \n",
    "    try:\n",
    "        alpha_is_epsilon = alpha.IsEpsilon\n",
    "    except:\n",
    "        alpha_is_epsilon = False\n",
    "    \n",
    "\n",
    "   \n",
    "    if alpha_is_epsilon:\n",
    "        first_alpha.set_epsilon()\n",
    "\n",
    "    else:\n",
    "        for i, x in enumerate(alpha):\n",
    "            if first_alpha.contains_epsilon:\n",
    "                first_alpha.set_epsilon(False)\n",
    "            if x.IsTerminal:\n",
    "                first_alpha.update(ContainerSet(x))\n",
    "                break\n",
    "            else:\n",
    "                first_alpha.hard_update(firsts[alpha[i]])\n",
    "                if not first_alpha.contains_epsilon:\n",
    "                    break\n",
    "    \n",
    "    return first_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes First(Vt) U First(Vn) U First(alpha)\n",
    "# P: X -> alpha\n",
    "def compute_firsts(G):\n",
    "    firsts = {}\n",
    "    change = True\n",
    "    \n",
    "    # init First(Vt)\n",
    "    for terminal in G.terminals:\n",
    "        firsts[terminal] = ContainerSet(terminal)\n",
    "        \n",
    "    # init First(Vn)\n",
    "    for nonterminal in G.nonTerminals:\n",
    "        firsts[nonterminal] = ContainerSet()\n",
    "    \n",
    "    while change:\n",
    "        change = False\n",
    "        \n",
    "        # P: X -> alpha\n",
    "        for production in G.Productions:\n",
    "            X = production.Left\n",
    "            alpha = production.Right\n",
    "            \n",
    "            # get current First(X)\n",
    "            first_X = firsts[X]\n",
    "                \n",
    "            # init First(alpha)\n",
    "            try:\n",
    "                first_alpha = firsts[alpha]\n",
    "            except KeyError:\n",
    "                first_alpha = firsts[alpha] = ContainerSet()\n",
    "            \n",
    "            # CurrentFirst(alpha)???\n",
    "            local_first = compute_local_first(firsts, alpha)\n",
    "            \n",
    "            # update First(X) and First(alpha) from CurrentFirst(alpha)\n",
    "            change |= first_alpha.hard_update(local_first)\n",
    "            change |= first_X.hard_update(local_first)\n",
    "                    \n",
    "    # First(Vt) + First(Vt) + First(RightSides)\n",
    "    return firsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def compute_follows(G, firsts):\n",
    "    follows = { }\n",
    "    change = True\n",
    "    \n",
    "    local_firsts = {}\n",
    "    \n",
    "    for nonterminal in G.nonTerminals:\n",
    "        follows[nonterminal] = ContainerSet()\n",
    "    follows[G.startSymbol] = ContainerSet(G.EOF)\n",
    "    \n",
    "    while change:\n",
    "        change = False\n",
    "        \n",
    "        # P: X -> alpha\n",
    "        for production in G.Productions:\n",
    "            X = production.Left\n",
    "            alpha = production.Right\n",
    "            \n",
    "            follow_X = follows[X]\n",
    "            \n",
    "            if alpha.IsEpsilon:\n",
    "                continue\n",
    "\n",
    "\n",
    "            for i, symbol in enumerate(alpha):\n",
    "                if(symbol.IsTerminal): \n",
    "                    continue\n",
    "                if(symbol.IsNonTerminal):\n",
    "                    \n",
    "                    if( i + 1 < len(alpha)):\n",
    "                        \n",
    "                        next_symbol = alpha[i+1]\n",
    "                        \n",
    "                            \n",
    "                        local_first = firsts[next_symbol]\n",
    "                           \n",
    "                               \n",
    "                        change |= follows[symbol].update(local_first)\n",
    "                        if local_first.contains_epsilon:\n",
    "                            change |= follows[symbol].update(follow_X)\n",
    "                    \n",
    "                    else:\n",
    "                        follows[alpha[-1]] = follow_X\n",
    "           \n",
    "    return follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_tokens = { lex: Token(lex, G[lex]) for lex in '+ - * / ( ) ^ = let in id ,'.split() }\n",
    "letHulk = LetHulk(G, fixed_tokens)\n",
    "letHulkfirsts = compute_firsts(G)\n",
    "letHulkFollows = compute_follows(G, letHulkfirsts)\n",
    "letHulkTable = build_parsing_table(G, letHulkfirsts, letHulkFollows)\n",
    "letHulkParser = metodo_predictivo_no_recursivo(G, letHulkTable, letHulkfirsts, letHulkFollows)\n",
    "tokenize_text = tokenizer(G, letHulk.fixed_tokens)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Tokens================\n",
      "[\n",
      "   let: let\n",
      "   id: x\n",
      "   =: =\n",
      "   num: 1\n",
      "   ,: ,\n",
      "   id: y\n",
      "   =: =\n",
      "   num: 2\n",
      "   in: in\n",
      "   num: 3\n",
      "   +: +\n",
      "   (: (\n",
      "   let: let\n",
      "   id: x\n",
      "   =: =\n",
      "   num: 4\n",
      "   ,: ,\n",
      "   id: z\n",
      "   =: =\n",
      "   num: 5\n",
      "   in: in\n",
      "   id: x\n",
      "   +: +\n",
      "   id: y\n",
      "   +: +\n",
      "   id: z\n",
      "   ): )\n",
      "   +: +\n",
      "   id: x\n",
      "   $: $\n",
      "]\n",
      "==============Left-Parse==============\n",
      "[\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> let V I\n",
      "   V -> id = E L\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "   L -> , V\n",
      "   V -> id = E L\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "   L -> e\n",
      "   I -> in E\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> + T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> ( E )\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> let V I\n",
      "   V -> id = E L\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "   L -> , V\n",
      "   V -> id = E L\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> num\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "   L -> e\n",
      "   I -> in E\n",
      "   E -> T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> id\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> + T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> id\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> + T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> id\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> + T X\n",
      "   T -> F Y\n",
      "   F -> A Z\n",
      "   A -> id\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "   Z -> e\n",
      "   Y -> e\n",
      "   X -> e\n",
      "]\n",
      "<class '__main__.AssignNode'>\n",
      "{'y': <__main__.ConstantNumberNode object at 0x107d59450>}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [83], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m expression \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlet x = 1 , y = 2 in 3 + ( let x = 4 , z = 5 in x + y + z ) + x\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m run_pipeline(expression, tokenize_text, \u001b[38;5;241m15\u001b[39m, letHulkParser, printer)\n",
      "Cell \u001b[0;32mIn [67], line 20\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(text, tokenizer, value, parser, formatter)\u001b[0m\n\u001b[1;32m     18\u001b[0m left_parse \u001b[38;5;241m=\u001b[39m parser(tokens)\n\u001b[1;32m     19\u001b[0m pprint(left_parse, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m==============Left-Parse==============\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m ast \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_parse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m pprint(formatter(ast), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=================AST==================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m result \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m<string>:13\u001b[0m, in \u001b[0;36mevaluate_parse\u001b[0;34m(f, J)\u001b[0m\n",
      "File \u001b[0;32m<string>:32\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(production, f, J, inherited_value)\u001b[0m\n",
      "File \u001b[0;32m<string>:32\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(production, f, J, inherited_value)\u001b[0m\n",
      "    \u001b[0;31m[... skipping similar frames: evaluate at line 32 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m<string>:32\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(production, f, J, inherited_value)\u001b[0m\n",
      "File \u001b[0;32m<string>:34\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(production, f, J, inherited_value)\u001b[0m\n",
      "Cell \u001b[0;32mIn [78], line 49\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(h, s)\u001b[0m\n\u001b[1;32m     44\u001b[0m Z \u001b[38;5;241m%\u001b[39m\u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39mEpsilon, \u001b[38;5;28;01mlambda\u001b[39;00m h,s: h[\u001b[38;5;241m0\u001b[39m]                 \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#                                                                         \u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#==========================={V --> id= EL}================================#\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m V \u001b[38;5;241m%\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m+\u001b[39m equal \u001b[38;5;241m+\u001b[39m E \u001b[38;5;241m+\u001b[39m L , \u001b[38;5;28;01mlambda\u001b[39;00m h,s : \u001b[43mAssignNode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#==========================={L --> ,V | epsilon}================================#\u001b[39;00m\n\u001b[1;32m     53\u001b[0m L \u001b[38;5;241m%\u001b[39m\u001b[38;5;241m=\u001b[39m comma \u001b[38;5;241m+\u001b[39m V , \u001b[38;5;28;01mlambda\u001b[39;00m h,s : s[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [77], line 24\u001b[0m, in \u001b[0;36mAssignNode.__init__\u001b[0;34m(self, id, value, assingNode)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(assingNode))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(assingNode\u001b[38;5;241m.\u001b[39mdic)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,j \u001b[38;5;129;01min\u001b[39;00m assingNode\u001b[38;5;241m.\u001b[39mdic:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(j, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvaloooooor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "expression = 'let x = 1 , y = 2 in 3 + ( let x = 4 , z = 5 in x + y + z ) + x'\n",
    "run_pipeline(expression, tokenize_text, 15, letHulkParser, printer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
